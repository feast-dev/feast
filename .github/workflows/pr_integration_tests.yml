name: pr-integration-tests

on:
  pull_request_target:
    types:
      - opened
      - synchronize
      - labeled

jobs:
  build-docker-image:
    # all jobs MUST have this if check for 'ok-to-test' or 'approved' for security purposes.
    if: (github.event.action == 'labeled' && (github.event.label.name == 'approved' || github.event.label.name == 'ok-to-test'))
      || (github.event.action != 'labeled' && (contains(github.event.pull_request.labels.*.name, 'ok-to-test') || contains(github.event.pull_request.labels.*.name, 'approved')))
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
        with:
          # pull_request_target runs the workflow in the context of the base repo
          # as such actions/checkout needs to be explicit configured to retrieve
          # code from the PR.
          ref: refs/pull/${{ github.event.pull_request.number }}/merge
          submodules: recursive
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v1
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v1
      - name: Set up AWS SDK
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-2
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1
      - name: Set ECR image tag
        id: image-tag
        run: echo '::set-output name=DOCKER_IMAGE_TAG::`git rev-parse HEAD`'
      - name: Build and push
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: feast-python-server
        run: |
          docker build \
            --file sdk/python/feast/infra/feature_servers/aws_lambda/Dockerfile \
            --tag $ECR_REGISTRY/$ECR_REPOSITORY:${{ steps.image-tag.outputs.DOCKER_IMAGE_TAG }} \
            .
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:${{ steps.image-tag.outputs.DOCKER_IMAGE_TAG }}
    outputs:
      DOCKER_IMAGE_TAG: ${{ steps.image-tag.outputs.DOCKER_IMAGE_TAG }}
  integration-test-python:
    # all jobs MUST have this if check for 'ok-to-test' or 'approved' for security purposes.
    if: (github.event.action == 'labeled' && (github.event.label.name == 'approved' || github.event.label.name == 'ok-to-test'))
      || (github.event.action != 'labeled' && (contains(github.event.pull_request.labels.*.name, 'ok-to-test') || contains(github.event.pull_request.labels.*.name, 'approved')))
    needs: build-docker-image
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        python-version: [ 3.7, 3.8, 3.9 ]
        os: [ ubuntu-latest ]
    env:
      OS: ${{ matrix.os }}
      PYTHON: ${{ matrix.python-version }}
    services:
      redis:
        image: redis
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - uses: actions/checkout@v2
        with:
          # pull_request_target runs the workflow in the context of the base repo
          # as such actions/checkout needs to be explicit configured to retrieve
          # code from the PR.
          ref: refs/pull/${{ github.event.pull_request.number }}/merge
          submodules: recursive
      - name: Setup Python
        uses: actions/setup-python@v2
        id: setup-python
        with:
          python-version: ${{ matrix.python-version }}
          architecture: x64
      - name: Set up gcloud SDK
        uses: google-github-actions/setup-gcloud@v0
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          service_account_key: ${{ secrets.GCP_SA_KEY }}
          export_default_credentials: true
      - name: Use gcloud CLI
        run: gcloud info
      - name: Set up AWS SDK
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-2
      - name: Use AWS CLI
        run: aws sts get-caller-identity
      - name: Upgrade pip version
        run: |
          pip install --upgrade "pip>=21.3.1"
      - name: Get pip cache dir
        id: pip-cache
        run: |
          echo "::set-output name=dir::$(pip cache dir)"
      - name: pip cache
        uses: actions/cache@v2
        with:
          path: |
            ${{ steps.pip-cache.outputs.dir }}
            /opt/hostedtoolcache/Python
            /Users/runner/hostedtoolcache/Python
          key: ${{ runner.os }}-${{ steps.setup-python.outputs.python-version }}-pip-${{ hashFiles('**/setup.py') }}
          restore-keys: |
            ${{ runner.os }}-${{ steps.setup-python.outputs.python-version }}-pip-
      - name: Install dependencies
        run: make install-python-ci-dependencies
      - name: Test python
        env:
          FEAST_SERVER_DOCKER_IMAGE_TAG: ${{ needs.build-docker-image.outputs.DOCKER_IMAGE_TAG }}
          FEAST_USAGE: "False"
          IS_TEST: "True"
        run: pytest -n 8 --cov=./ --cov-report=xml --verbose --color=yes sdk/python/tests --integration --durations=5
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v1
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage.xml
          flags: integrationtests
          env_vars: OS,PYTHON
          fail_ci_if_error: true
          verbose: true
      - name: Benchmark python
        run: FEAST_USAGE=False IS_TEST=True pytest --verbose --color=yes sdk/python/tests --integration --benchmark --benchmark-autosave --benchmark-save-data --durations=5
      - name: Upload Benchmark Artifact to S3
        run: aws s3 cp --recursive .benchmarks s3://feast-ci-pytest-benchmarks

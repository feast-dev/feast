//
// Copyright 2018 The Feast Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//

syntax = "proto3";
package feast.core;

option go_package = "github.com/feast-dev/feast/sdk/go/protos/feast/core";
option java_outer_classname = "JobServiceProto";
option java_package = "feast.proto.core";

import "google/protobuf/timestamp.proto";
import "feast/core/DataSource.proto";
import "feast/serving/ServingService.proto";

service JobService {
    // Start job to ingest data from offline store into online store
    rpc StartOfflineToOnlineIngestionJob (StartOfflineToOnlineIngestionJobRequest) returns (StartOfflineToOnlineIngestionJobResponse);

    // Produce a training dataset, return a job id that will provide a file reference
    rpc GetHistoricalFeatures (GetHistoricalFeaturesRequest) returns (GetHistoricalFeaturesResponse);

    // Start job to ingest data from stream into online store
    rpc StartStreamToOnlineIngestionJob (StartStreamToOnlineIngestionJobRequest) returns (StartStreamToOnlineIngestionJobResponse);

    // List all types of jobs
    rpc ListJobs (ListJobsRequest) returns (ListJobsResponse);

    // Stop a single job
    rpc StopJob (StopJobRequest) returns (StopJobResponse);

    // Get details of a single job
    rpc GetJob (GetJobRequest) returns (GetJobResponse);
}


enum JobType {
	INVALID_JOB = 0;
	OFFLINE_TO_ONLINE_JOB = 1;
	STREAM_TO_ONLINE_JOB = 2;
	EXPORT_JOB = 4;
}

enum JobStatus {
	JOB_STATUS_INVALID = 0;
       // The Job has be registered and waiting to get scheduled to run
	JOB_STATUS_PENDING = 1;
       // The Job is currently processing its task
	JOB_STATUS_RUNNING = 2;
       // The Job has successfully completed its task
	JOB_STATUS_DONE = 3;
       // The Job has encountered an error while processing its task
	JOB_STATUS_ERROR = 4;
}

message Job {
  // Identifier of the Job
  string id = 1;
  // External Identifier of the Job assigned by the Spark executor
  string external_id = 2;
  // Type of the Job
  JobType type = 3;
  // Current job status
  JobStatus status = 4;
  // Timestamp on when the job was is created
  google.protobuf.Timestamp created_timestamp = 5;
  // Timestamp on when the job has stopped.
  google.protobuf.Timestamp stop_timestamp = 6;

  message ExportJobMeta {
    // Glob of the exported files that should be retrieved to reconstruct
    // the dataframe with retrieved features.
    repeated string file_glob = 1;
    // The Historical Features request that triggered this export job
    GetHistoricalFeaturesRequest request = 2;
  }

  message OfflineToOnlineMeta {
    // Reference to the Feature Table being populated by this job
    string project = 1;
    string table_name = 2;
  }

  message StreamToOnlineMeta {
    // Reference to the Feature Table being populated by this job
    string project = 1;
    string table_name = 2;
  }

  // JobType specific metadata on the job
  oneof meta {
    ExportJobMeta export = 7;
    OfflineToOnlineMeta offline_to_online = 8;
    StreamToOnlineMeta stream_to_online = 9;
  }
}

// Ingest data from offline store into online store
message StartOfflineToOnlineIngestionJobRequest {
    // Feature table to ingest
    string project = 1;
    string table_name = 2;

    // Start of time range for source data from offline store
    google.protobuf.Timestamp start_date = 3;

    // End of time range for source data from offline store
    google.protobuf.Timestamp end_date = 4;
}

message StartOfflineToOnlineIngestionJobResponse {
    // Job ID assigned by Feast
    string id = 1;
}

message GetHistoricalFeaturesRequest {
  // List of feature references that are being retrieved
  repeated string feature_refs = 1;

  // Batch DataSource that can be used to obtain entity values for historical retrieval.
  // For each entity value, a feature value will be retrieved for that value/timestamp
  // Only 'BATCH_*' source types are supported.
  // Currently only BATCH_FILE source type is supported.
  DataSource entities_source = 2;

  // Optional field to specify project name override. If specified, uses the
  // given project for retrieval. Overrides the projects specified in
  // Feature References if both are specified.
  string project = 3;

  // Specifies the path in a bucket to write the exported feature data files
  // Export to AWS S3 - s3://path/to/features
  // Export to GCP GCS -  gs://path/to/features
  string destination_path = 4;
}

message GetHistoricalFeaturesResponse {
    // Export Job with ID assigned by Feast
    string id = 1;
}

message StartStreamToOnlineIngestionJobRequest {
    // Feature table to ingest
    string project = 1;
    string table_name = 2;
}

message StartStreamToOnlineIngestionJobResponse {
    // Job ID assigned by Feast
    string id = 1;
}

message ListJobsRequest {
  Filter filter = 1;
  message Filter {
    // Filter jobs by job type
    JobType type = 1;
    // Filter jobs by current job status
    JobStatus status = 2;
  }
}

message ListJobsResponse {
  repeated Job jobs = 1;
}

message GetJobRequest {
  string job_id = 1;
}

message GetJobResponse {
  Job job = 1;
}

message RestartJobRequest {
  string job_id = 1;
}

message RestartJobResponse {}

message StopJobRequest{
  string job_id = 1;
}

message StopJobResponse {}
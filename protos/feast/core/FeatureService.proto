syntax = "proto3";
package feast.core;

option go_package = "github.com/feast-dev/feast/go/protos/feast/core";
option java_outer_classname = "FeatureServiceProto";
option java_package = "feast.proto.core";

import "google/protobuf/timestamp.proto";
import "feast/core/FeatureViewProjection.proto";

message FeatureService {
  // User-specified specifications of this feature service.
  FeatureServiceSpec spec = 1;

  // System-populated metadata for this feature service.
  FeatureServiceMeta meta = 2;
}

message FeatureServiceSpec {
  // Name of the Feature Service. Must be unique. Not updated.
  string name = 1;

  // Name of Feast project that this Feature Service belongs to.
  string project = 2;

  // Represents a projection that's to be applied on top of the FeatureView.
  // Contains data such as the features to use from a FeatureView.
  repeated FeatureViewProjection features = 3;

  // User defined metadata
  map<string,string> tags = 4;

  // Description of the feature service.
  string description = 5;

  // Owner of the feature service.
  string owner = 6;

  // (optional) if provided logging will be enabled for this feature service.
  LoggingConfig logging_config = 7;
}


message FeatureServiceMeta {
  // Time where this Feature Service is created
  google.protobuf.Timestamp created_timestamp = 1;

  // Time where this Feature Service is last updated
  google.protobuf.Timestamp last_updated_timestamp = 2;

}


message LoggingConfig {
  float sample_rate = 1;

  oneof destination {
    FileDestination file_destination = 3;
    BigQueryDestination bigquery_destination = 4;
    RedshiftDestination redshift_destination = 5;
    SnowflakeDestination snowflake_destination = 6;
    CustomDestination custom_destination = 7;
    AthenaDestination athena_destination = 8;
  }

  message FileDestination {
    string path = 1;
    string s3_endpoint_override = 2;

    // column names to use for partitioning
    repeated string partition_by = 3;
  }

  message BigQueryDestination {
    // Full table reference in the form of [project:dataset.table]
    string table_ref = 1;
  }

  message RedshiftDestination {
    // Destination table name. ClusterId and database will be taken from an offline store config
    string table_name = 1;
  }

  message AthenaDestination {
    // Destination table name. data_source and database will be taken from an offline store config
    string table_name = 1;
  }

  message SnowflakeDestination {
    // Destination table name. Schema and database will be taken from an offline store config
    string table_name = 1;
  }

  message CustomDestination {
    string kind = 1;
    map<string, string> config = 2;
  }
}

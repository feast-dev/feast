#
# Copyright 2018 The Feast Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
#

feast:
  # GRPC service address for Feast Core
  # Feast Job Controller requires connection to Feast Core to retrieve and reload Feast metadata.
  core-host: localhost
  core-port: 6565

  jobs:
    # Enabling JobManagement
    enabled: true

    # Configurable Prefix for JobId to allow jobs working in parallel to separate their Kafka consumer groups
    job_id_prefix: ""

    # Job update polling interval in milliseconds: how often Feast checks if new jobs should be sent to the runner.
    polling_interval_milliseconds: 60000

    # Timeout in seconds for each attempt to update or submit a new job to the runner.
    job_update_timeout_seconds: 240

    # Name of the active runner in "runners" that should be used. Only a single runner can be active at one time.
    active_runner: direct

    # List of runner configurations. Please see protos/feast/core/Runner.proto for more details
    runners:
      - name: direct
        type: DirectRunner
        # Direct runner options. See also for docs on options:
        # https://api.docs.feast.dev/grpc/feast.core.pb.html#DirectRunnerConfigOptions
        options:
          tempLocation: gs://bucket/tempLocation

      - name: dataflow
        type: DataflowRunner
        # Dataflow runner options. See also for docs on options:
        # https://api.docs.feast.dev/grpc/feast.core.pb.html#DataflowRunnerConfigOptions
        options:
          project: my_gcp_project
          region: asia-east1
          workerZone: asia-east1-a
          tempLocation: gs://bucket/tempLocation
          network: default
          subnetwork: regions/asia-east1/subnetworks/mysubnetwork
          maxNumWorkers: 1
          enableStreamingEngine: false
          workerDiskType: compute.googleapis.com/projects/asia-east1-a/diskTypes/pd-ssd
          autoscalingAlgorithm: THROUGHPUT_BASED
          usePublicIps: false
          workerMachineType: n1-standard-1
          deadLetterTableSpec: project_id:dataset_id.table_id
          kafkaConsumerProperties:
            "[max.poll.records]": "50000"
            "[receive.buffer.bytes]": "33554432"

    # Configuration options for metric collection for all ingestion jobs
    metrics:
      # Enable metrics pushing for all ingestion jobs.
      enabled: false
      # Type of metrics sink. Only statsd is currently supported.
      type: statsd
      # Host of the metrics sink.
      host: localhost
      # Port of the metrics sink.
      port: 9125

    controller:
      # if true one job per source with many stores would be created
      # if false one job per source-store pair would be created
      consolidate-jobs-per-source: false

      # labels (map) that being assigned to job on creation.
      # And also used to determine jobs that are being managed by current application
      # among all running jobs
      jobSelector:
        application: feast

      # Specify feature sets that should be handled by current instance of JobManager
      featureSetSelector:
        - project: "*"
          name: "*"
      # Stores names that are enabled on current instance of JobManager
      whitelisted-stores:
        - historical
        - online
        - online_cluster

  stream:
    # Feature stream type. Only kafka is supported.
    type: kafka
    # Feature stream options.
    # See the following for options https://api.docs.feast.dev/grpc/feast.core.pb.html#KafkaSourceConfig
    options:
      topic: feast-features
      bootstrapServers: localhost:9092
      replicationFactor: 1
      partitions: 1
    # Feast Job Controller uses Kafka to push FeatureSets to Ingestion Jobs.
    # FeatureSet push options. 
    specsOptions:
      # Kafka topic to use to push FeatureSets.
      specsTopic: feast-specs
      # Kafka topic to use to obtain acknowledgment on FeatureSets push.
      specsAckTopic: feast-specs-ack
      # Time interval between pushing FeatureSets.
      notifyIntervalMilliseconds: 1000
        
  logging:
    # Audit logging provides a machine readable structured JSON log that can give better 
    # insight into what is happening in Feast.
    audit:
      # Whether audit logging is enabled. 
      enabled: true
      # Whether to enable message level (ie request/response) audit logging
      messageLogging:
        enabled: false
        # Logging forwarder currently provides a machine readable structured JSON log to an
        # external fluentd service that can give better insight into what is happening in Feast.
        # Accepts console / fluentd as destination
        destination: console
        fluentdHost: localhost
        fluentdPort: 24224

grpc:
  server:
    # The port that Feast Core gRPC service listens on
    port: 6570
    security:
      enabled: false
      certificateChain: server.crt
      privateKey: server.key

management:
  metrics:
    export:
      simple:
        enabled: false
      statsd:
        enabled: true
        host: ${STATSD_HOST:localhost}
        port: ${STATSD_PORT:8125}

server:
  # The port number on which the Tomcat webserver that serves REST API endpoints should listen
  # Set default value avoiding conflicts with core & serving
  port: ${SERVER_PORT:8082}

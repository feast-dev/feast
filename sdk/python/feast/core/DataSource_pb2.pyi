"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
from feast.core.DataFormat_pb2 import (
    FileFormat as feast___core___DataFormat_pb2___FileFormat,
    StreamFormat as feast___core___DataFormat_pb2___StreamFormat,
)

from google.protobuf.descriptor import (
    Descriptor as google___protobuf___descriptor___Descriptor,
    EnumDescriptor as google___protobuf___descriptor___EnumDescriptor,
    FileDescriptor as google___protobuf___descriptor___FileDescriptor,
)

from google.protobuf.internal.containers import (
    ScalarMap as google___protobuf___internal___containers___ScalarMap,
)

from google.protobuf.internal.enum_type_wrapper import (
    _EnumTypeWrapper as google___protobuf___internal___enum_type_wrapper____EnumTypeWrapper,
)

from google.protobuf.message import (
    Message as google___protobuf___message___Message,
)

from typing import (
    Mapping as typing___Mapping,
    NewType as typing___NewType,
    Optional as typing___Optional,
    Text as typing___Text,
    cast as typing___cast,
)

from typing_extensions import (
    Literal as typing_extensions___Literal,
)


builtin___bool = bool
builtin___bytes = bytes
builtin___float = float
builtin___int = int


DESCRIPTOR: google___protobuf___descriptor___FileDescriptor = ...

class DataSource(google___protobuf___message___Message):
    DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
    SourceTypeValue = typing___NewType('SourceTypeValue', builtin___int)
    type___SourceTypeValue = SourceTypeValue
    SourceType: _SourceType
    class _SourceType(google___protobuf___internal___enum_type_wrapper____EnumTypeWrapper[DataSource.SourceTypeValue]):
        DESCRIPTOR: google___protobuf___descriptor___EnumDescriptor = ...
        INVALID = typing___cast(DataSource.SourceTypeValue, 0)
        BATCH_FILE = typing___cast(DataSource.SourceTypeValue, 1)
        BATCH_BIGQUERY = typing___cast(DataSource.SourceTypeValue, 2)
        STREAM_KAFKA = typing___cast(DataSource.SourceTypeValue, 3)
        STREAM_KINESIS = typing___cast(DataSource.SourceTypeValue, 4)
    INVALID = typing___cast(DataSource.SourceTypeValue, 0)
    BATCH_FILE = typing___cast(DataSource.SourceTypeValue, 1)
    BATCH_BIGQUERY = typing___cast(DataSource.SourceTypeValue, 2)
    STREAM_KAFKA = typing___cast(DataSource.SourceTypeValue, 3)
    STREAM_KINESIS = typing___cast(DataSource.SourceTypeValue, 4)

    class FieldMappingEntry(google___protobuf___message___Message):
        DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
        key: typing___Text = ...
        value: typing___Text = ...

        def __init__(self,
            *,
            key : typing___Optional[typing___Text] = None,
            value : typing___Optional[typing___Text] = None,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions___Literal[u"key",b"key",u"value",b"value"]) -> None: ...
    type___FieldMappingEntry = FieldMappingEntry

    class FileOptions(google___protobuf___message___Message):
        DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
        file_url: typing___Text = ...

        @property
        def file_format(self) -> feast___core___DataFormat_pb2___FileFormat: ...

        def __init__(self,
            *,
            file_format : typing___Optional[feast___core___DataFormat_pb2___FileFormat] = None,
            file_url : typing___Optional[typing___Text] = None,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions___Literal[u"file_format",b"file_format"]) -> builtin___bool: ...
        def ClearField(self, field_name: typing_extensions___Literal[u"file_format",b"file_format",u"file_url",b"file_url"]) -> None: ...
    type___FileOptions = FileOptions

    class BigQueryOptions(google___protobuf___message___Message):
        DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
        table_ref: typing___Text = ...

        def __init__(self,
            *,
            table_ref : typing___Optional[typing___Text] = None,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions___Literal[u"table_ref",b"table_ref"]) -> None: ...
    type___BigQueryOptions = BigQueryOptions

    class KafkaOptions(google___protobuf___message___Message):
        DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
        bootstrap_servers: typing___Text = ...
        topic: typing___Text = ...

        @property
        def message_format(self) -> feast___core___DataFormat_pb2___StreamFormat: ...

        def __init__(self,
            *,
            bootstrap_servers : typing___Optional[typing___Text] = None,
            topic : typing___Optional[typing___Text] = None,
            message_format : typing___Optional[feast___core___DataFormat_pb2___StreamFormat] = None,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions___Literal[u"message_format",b"message_format"]) -> builtin___bool: ...
        def ClearField(self, field_name: typing_extensions___Literal[u"bootstrap_servers",b"bootstrap_servers",u"message_format",b"message_format",u"topic",b"topic"]) -> None: ...
    type___KafkaOptions = KafkaOptions

    class KinesisOptions(google___protobuf___message___Message):
        DESCRIPTOR: google___protobuf___descriptor___Descriptor = ...
        region: typing___Text = ...
        stream_name: typing___Text = ...

        @property
        def record_format(self) -> feast___core___DataFormat_pb2___StreamFormat: ...

        def __init__(self,
            *,
            region : typing___Optional[typing___Text] = None,
            stream_name : typing___Optional[typing___Text] = None,
            record_format : typing___Optional[feast___core___DataFormat_pb2___StreamFormat] = None,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions___Literal[u"record_format",b"record_format"]) -> builtin___bool: ...
        def ClearField(self, field_name: typing_extensions___Literal[u"record_format",b"record_format",u"region",b"region",u"stream_name",b"stream_name"]) -> None: ...
    type___KinesisOptions = KinesisOptions

    type: type___DataSource.SourceTypeValue = ...
    event_timestamp_column: typing___Text = ...
    date_partition_column: typing___Text = ...
    created_timestamp_column: typing___Text = ...

    @property
    def field_mapping(self) -> google___protobuf___internal___containers___ScalarMap[typing___Text, typing___Text]: ...

    @property
    def file_options(self) -> type___DataSource.FileOptions: ...

    @property
    def bigquery_options(self) -> type___DataSource.BigQueryOptions: ...

    @property
    def kafka_options(self) -> type___DataSource.KafkaOptions: ...

    @property
    def kinesis_options(self) -> type___DataSource.KinesisOptions: ...

    def __init__(self,
        *,
        type : typing___Optional[type___DataSource.SourceTypeValue] = None,
        field_mapping : typing___Optional[typing___Mapping[typing___Text, typing___Text]] = None,
        event_timestamp_column : typing___Optional[typing___Text] = None,
        date_partition_column : typing___Optional[typing___Text] = None,
        created_timestamp_column : typing___Optional[typing___Text] = None,
        file_options : typing___Optional[type___DataSource.FileOptions] = None,
        bigquery_options : typing___Optional[type___DataSource.BigQueryOptions] = None,
        kafka_options : typing___Optional[type___DataSource.KafkaOptions] = None,
        kinesis_options : typing___Optional[type___DataSource.KinesisOptions] = None,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions___Literal[u"bigquery_options",b"bigquery_options",u"file_options",b"file_options",u"kafka_options",b"kafka_options",u"kinesis_options",b"kinesis_options",u"options",b"options"]) -> builtin___bool: ...
    def ClearField(self, field_name: typing_extensions___Literal[u"bigquery_options",b"bigquery_options",u"created_timestamp_column",b"created_timestamp_column",u"date_partition_column",b"date_partition_column",u"event_timestamp_column",b"event_timestamp_column",u"field_mapping",b"field_mapping",u"file_options",b"file_options",u"kafka_options",b"kafka_options",u"kinesis_options",b"kinesis_options",u"options",b"options",u"type",b"type"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions___Literal[u"options",b"options"]) -> typing_extensions___Literal["file_options","bigquery_options","kafka_options","kinesis_options"]: ...
type___DataSource = DataSource

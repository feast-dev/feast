{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from feast.sdk.resources.entity import Entity\n",
    "from feast.sdk.resources.storage import Storage\n",
    "from feast.sdk.resources.feature import Feature, Datastore, ValueType, Granularity\n",
    "from feast.sdk.resources.feature_set import FeatureSet, FileType\n",
    "import feast.specs.FeatureSpec_pb2 as feature_pb\n",
    "\n",
    "from feast.sdk.importer import Importer\n",
    "\n",
    "from feast.sdk.client import Client, ServingRequestType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature engineering steps \n",
    "## Referenced from https://www.kaggle.com/karelrv/nyct-from-a-to-z-with-xgboost-tutorial/notebook\n",
    "\n",
    "def haversine_array(lat1, lng1, lat2, lng2):\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n",
    "    return h\n",
    "\n",
    "def dummy_manhattan_distance(lat1, lng1, lat2, lng2):\n",
    "    a = haversine_array(lat1, lng1, lat1, lng2)\n",
    "    b = haversine_array(lat1, lng1, lat2, lng1)\n",
    "    return a + b\n",
    "\n",
    "def bearing_array(lat1, lng1, lat2, lng2):\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lng_delta_rad = np.radians(lng2 - lng1)\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    y = np.sin(lng_delta_rad) * np.cos(lat2)\n",
    "    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n",
    "    return np.degrees(np.arctan2(y, x))\n",
    "\n",
    "df = pd.read_csv('taxi_small.csv')\n",
    "df['pickup_datetime'] = pd.to_datetime(df.pickup_datetime)\n",
    "df['dropoff_datetime'] = pd.to_datetime(df.dropoff_datetime)\n",
    "df['log_trip_duration'] = np.log(df['trip_duration'].values + 1)\n",
    "\n",
    "# location features\n",
    "df.loc[:, 'distance_haversine'] = haversine_array(df['pickup_latitude'].values, df['pickup_longitude'].values, df['dropoff_latitude'].values, df['dropoff_longitude'].values)\n",
    "df.loc[:, 'distance_dummy_manhattan'] =  dummy_manhattan_distance(df['pickup_latitude'].values, df['pickup_longitude'].values, df['dropoff_latitude'].values, df['dropoff_longitude'].values)\n",
    "df.loc[:, 'direction'] = bearing_array(df['pickup_latitude'].values, df['pickup_longitude'].values, df['dropoff_latitude'].values, df['dropoff_longitude'].values)\n",
    "\n",
    "# time features\n",
    "df['month'] = df['pickup_datetime'].dt.month\n",
    "df['day_of_month'] = df['pickup_datetime'].dt.day\n",
    "df['hour'] = df['pickup_datetime'].dt.hour\n",
    "df['day_of_week'] = df['pickup_datetime'].dt.dayofweek\n",
    "\n",
    "# one hot encoding\n",
    "vendor = pd.get_dummies(df['vendor_id'], prefix='vi', prefix_sep='_')\n",
    "store_and_fwd_flag = pd.get_dummies(df['store_and_fwd_flag'], prefix='sf', prefix_sep='_')\n",
    "\n",
    "df = df.drop(['trip_duration','vendor_id','passenger_count','store_and_fwd_flag', 'dropoff_datetime',\n",
    "           'pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude'],axis = 1)\n",
    "df.columns = ['ride'] + list(df.columns[1:])\n",
    "df_complete = pd.concat([df, vendor, store_and_fwd_flag], axis=1)\n",
    "df_complete.columns = [col.lower() for col in df_complete.columns]\n",
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingesting into Feast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FEAST_CORE_URL = 'localhost:6565'\n",
    "FEAST_SERVING_URL = 'localhost:6566'\n",
    "STAGING_LOCATION = 'gs://feast-bucket/staging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now that we have finished creating our features, we ingest them into feast\n",
    "\n",
    "# Initialise client\n",
    "fs = Client(core_url=FEAST_CORE_URL, verbose=True)\n",
    "\n",
    "serving_ds=Datastore(id='REDIS1')\n",
    "warehouse_ds=Datastore(id='NOOP')\n",
    "\n",
    "# Create importer\n",
    "importer = Importer.from_df(df_complete, \n",
    "                           entity='ride', \n",
    "                           granularity=Granularity.NONE,\n",
    "                           owner='user@website.com',  \n",
    "                           staging_location=STAGING_LOCATION,\n",
    "                           id_column='ride', \n",
    "                           timestamp_column='pickup_datetime',\n",
    "                           serving_store=serving_ds,\n",
    "                           warehouse_store=warehouse_ds)\n",
    "\n",
    "# Update feature and entity metadata. Ideally you want to update these manually\n",
    "# so that they contain adequate information for the next user\n",
    "importer.entity.description = 'nyc taxi dataset' \n",
    "for feature_id in importer.features:\n",
    "    importer.features[feature_id].description = 'nyc taxi dataset'\n",
    "    \n",
    "# Ingest the feature data into the store\n",
    "fs.run(importer, apply_features=True, apply_entity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a training dataset\n",
    "\n",
    "Creating a training dataset allows you to isolate the data that goes into the model training step, allowing for reproduction and traceability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieving data: Training\n",
    "\n",
    "feature_set = FeatureSet(entity=\"ride\", \n",
    "                         features=[\"ride.none.log_trip_duration\", \n",
    "                                  \"ride.none.distance_haversine\",\n",
    "                                  \"ride.none.distance_dummy_manhattan\",\n",
    "                                  \"ride.none.direction\",\n",
    "                                  \"ride.none.month\",\n",
    "                                  \"ride.none.day_of_month\",\n",
    "                                  \"ride.none.hour\",\n",
    "                                  \"ride.none.day_of_week\",\n",
    "                                  \"ride.none.vi_1\",\n",
    "                                  \"ride.none.vi_2\",\n",
    "                                  \"ride.none.sf_n\",\n",
    "                                  \"ride.none.sf_y\"])\n",
    "dataset_info = fs.create_dataset(feature_set, \"2016-06-01\", \"2016-08-01\")\n",
    "dataset = fs.download_dataset_to_df(dataset_info, staging_location=STAGING_LOCATION)\n",
    "\n",
    "dataset.head()\n",
    "\n",
    "# train your model\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving serving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieving data: Serving\n",
    "\n",
    "# set serving endpoint\n",
    "fs = Client(serving_url=FEAST_SERVING_URL, verbose=True)\n",
    "\n",
    "feature_set = FeatureSet(entity=\"ride\", \n",
    "                         features=[\"ride.none.log_trip_duration\", \n",
    "                                  \"ride.none.distance_haversine\",\n",
    "                                  \"ride.none.distance_dummy_manhattan\",\n",
    "                                  \"ride.none.direction\",\n",
    "                                  \"ride.none.month\",\n",
    "                                  \"ride.none.day_of_month\",\n",
    "                                  \"ride.none.hour\",\n",
    "                                  \"ride.none.day_of_week\",\n",
    "                                  \"ride.none.vi_1\",\n",
    "                                  \"ride.none.vi_2\",\n",
    "                                  \"ride.none.sf_n\",\n",
    "                                  \"ride.none.sf_y\"])\n",
    "\n",
    "# retrieve features\n",
    "feats = fs.get_serving_data(feature_set, entity_keys=[\"id2875421\",\"id1244481\"])\n",
    "\n",
    "# Feed data into model\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

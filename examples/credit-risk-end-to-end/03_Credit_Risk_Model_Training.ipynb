{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f2ab19-68e1-4725-b6e7-efd8eedebe1a",
   "metadata": {},
   "source": [
    "<center><img src=https://raw.githubusercontent.com/feast-dev/feast/master/docs/assets/feast_logo.png width=400/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a40de4-65cf-4b45-b321-2b7ce571f8cb",
   "metadata": {},
   "source": [
    "# Credit Risk Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe641d83-1e28-4f7f-895c-8ca038f6cc53",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f04f635-401b-47b6-b807-df61d42ec752",
   "metadata": {},
   "source": [
    "AI models have played a central role in modern credit risk assessment systems. In this example, we develop a credit risk model to predict whether a future loan will be good or bad, given some context data (presumably supplied from the loan application process). We use the modeling process to demonstrate how Feast can be used to facilitate the serving of data for training and inference use-cases.\n",
    "\n",
    "In this notebook, we train our AI model. We will use the popular scikit-learn library (sklearn) to train a RandomForestClassifier, as this is a relatively easy choice for a baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96bf1aa-c450-4201-83a4-e25b08bdd12d",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b33bc-bc06-4de0-8f3a-beea8179035c",
   "metadata": {},
   "source": [
    "*The following code assumes that you have read the example README.md file, and that you have setup an environment where the code can be run. Please make sure you have addressed the prerequisite needs.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c66a3dab-fdbf-40be-8227-6180dc314a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "import datetime\n",
    "import feast\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from feast import FeatureStore, RepoConfig\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a841445-fa47-4826-a874-28ac0e4ea57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23579727-7797-4101-a70d-b0d4c24b0fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed\n",
    "SEED = 142"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5be519-7733-449b-8dc3-411e86371315",
   "metadata": {},
   "source": [
    "This notebook assumes that you have already done the following:\n",
    "\n",
    "1. Run the [01_Credit_Risk_Data_Prep.ipynb](01_Credit_Risk_Data_Prep.ipynb) notebook to prepare the data.\n",
    "2. Run the [02_Deploying_the_Feature_Store.ipynb](02_Deploying_the_Feature_Store.ipynb) notebook to configure the feature stores and launch the feature store servers.\n",
    "\n",
    "If you have not completed the above steps, please go back and do so before continuing. This notebook relies on the data prepared by 1, and it uses the Feast offline server stood up by 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca99047-e508-4b1f-9f4c-f11e38587d70",
   "metadata": {},
   "source": [
    "### Get Label (Outcome) Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b49268-b7a5-4abc-8d82-1cdbf9bb4473",
   "metadata": {},
   "source": [
    "From our previous data exploration, remember that the label data represents whether the loan was classed as \"good\" (1) or \"bad\" (0). Let's pull the labels for training, as we will use them as our \"entity dataframe\" when pulling features.\n",
    "\n",
    "This is also a good time to remember that the label timestamps are lagged by 30-90 days from the context data records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a227a12-7b3e-462a-8f6e-38a7690df1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_parquet(\"Feature_Store/data/train_y.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31a39cad-0a85-4d98-ad95-008c81bb6fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>class</th>\n",
       "      <th>outcome_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-25 06:50:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>764</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-11-03 09:10:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-30 10:06:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-17 19:37:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-12-01 00:01:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  class   outcome_timestamp\n",
       "0   18    0.0 2023-11-25 06:50:13\n",
       "1  764    1.0 2023-11-03 09:10:13\n",
       "2  504    0.0 2023-11-30 10:06:03\n",
       "3  454    0.0 2023-11-17 19:37:19\n",
       "4  453    1.0 2023-12-01 00:01:48"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f29fd-46d3-444b-b24f-eaccd82ab7d3",
   "metadata": {},
   "source": [
    "### Pull Feature Data from Feast Offline Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c13b69-3d26-484c-97cd-97734cc812bd",
   "metadata": {},
   "source": [
    "In order to pull feature data from the offline store, we create a FeatureStore object that connects to the offline server (continuously running in the previous notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e9828f8-f210-4586-ac36-3f7e17f4f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FeatureStore object\n",
    "# (connects to the offline server deployed in 02_Deploying_the_Feature_Store.ipynb) \n",
    "store = FeatureStore(config=RepoConfig(\n",
    "    project=\"loan_applications\",\n",
    "    provider=\"local\",\n",
    "    registry=\"Feature_Store/data/registry.db\",\n",
    "    offline_store={\n",
    "        \"type\": \"remote\",\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": 8815\n",
    "    },\n",
    "    entity_key_serialization_version=2\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c007e7ca-40c1-4850-abed-73b6171ad08d",
   "metadata": {},
   "source": [
    "Now, we can retrieve feature data by supplying our entity dataframe and feature specifications to the `get_historical_features` function. Note that this function performs a fuzzy lookback (\"point-in-time\") join, matching the lagged outcome timestamp to the closest application timestamp (per ID) in the context data; it also joins the \"a\" and \"b\" features that we had previously split into two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd2e3cb5-c865-48f4-80b6-8a14a1ff09ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:_list_feature_views will make breaking changes. Please use _list_batch_feature_views instead. _list_feature_views will behave like _list_all_feature_views in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using outcome_timestamp as the event timestamp. To specify a column explicitly, please name it event_timestamp.\n"
     ]
    }
   ],
   "source": [
    "# Get feature data\n",
    "# (Joins a and b data, and selects the right timestamp--in this case their is only one each)\n",
    "features = store.get_historical_features(\n",
    "    entity_df=labels,\n",
    "    features=[\n",
    "        \"data_a:duration\",\n",
    "        \"data_a:credit_amount\",\n",
    "        \"data_a:installment_commitment\",\n",
    "        \"data_a:checking_status_ord\",\n",
    "        \"data_b:residence_since\",\n",
    "        \"data_b:age\",\n",
    "        \"data_b:existing_credits\",\n",
    "        \"data_b:num_dependents\",\n",
    "        \"data_b:housing_ord\"\n",
    "    ]\n",
    ").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c72f6cb1-bbbf-4512-98cd-0abe5ff0c24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   ID                      800 non-null    int64              \n",
      " 1   class                   800 non-null    float64            \n",
      " 2   outcome_timestamp       800 non-null    datetime64[ns, UTC]\n",
      " 3   duration                800 non-null    float64            \n",
      " 4   credit_amount           800 non-null    float64            \n",
      " 5   installment_commitment  800 non-null    float64            \n",
      " 6   checking_status_ord     800 non-null    float64            \n",
      " 7   residence_since         800 non-null    float64            \n",
      " 8   age                     800 non-null    float64            \n",
      " 9   existing_credits        800 non-null    float64            \n",
      " 10  num_dependents          800 non-null    float64            \n",
      " 11  housing_ord             800 non-null    float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(10), int64(1)\n",
      "memory usage: 75.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Check the data info (800 training records)\n",
    "features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ec3cda-1078-4dad-ac72-157265fea575",
   "metadata": {},
   "source": [
    "Let's list some records. The retrieval does reorder the data, so we use the labels ID column here to filter the same IDs from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e31bdfa6-a94d-479e-b46d-8990a9830c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>class</th>\n",
       "      <th>outcome_timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>installment_commitment</th>\n",
       "      <th>checking_status_ord</th>\n",
       "      <th>residence_since</th>\n",
       "      <th>age</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>housing_ord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>764</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-11-03 09:10:13+00:00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2463.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-30 10:06:03+00:00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1207.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-25 06:50:13+00:00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12579.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-12-01 00:01:48+00:00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2670.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-17 19:37:19+00:00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4817.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  class         outcome_timestamp  duration  credit_amount  \\\n",
       "230  764    1.0 2023-11-03 09:10:13+00:00      24.0         2463.0   \n",
       "500  504    0.0 2023-11-30 10:06:03+00:00      24.0         1207.0   \n",
       "538   18    0.0 2023-11-25 06:50:13+00:00      24.0        12579.0   \n",
       "584  453    1.0 2023-12-01 00:01:48+00:00      24.0         2670.0   \n",
       "614  454    0.0 2023-11-17 19:37:19+00:00      24.0         4817.0   \n",
       "\n",
       "     installment_commitment  checking_status_ord  residence_since   age  \\\n",
       "230                     4.0                  3.0              3.0  27.0   \n",
       "500                     4.0                  1.0              4.0  24.0   \n",
       "538                     4.0                  0.0              2.0  44.0   \n",
       "584                     4.0                  3.0              4.0  35.0   \n",
       "614                     2.0                  1.0              3.0  31.0   \n",
       "\n",
       "     existing_credits  num_dependents  housing_ord  \n",
       "230               2.0             1.0          1.0  \n",
       "500               1.0             1.0          2.0  \n",
       "538               1.0             1.0          0.0  \n",
       "584               1.0             1.0          1.0  \n",
       "614               1.0             1.0          1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check some data records\n",
    "features.loc[features.ID.isin(labels.ID.head())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5599747f-ae6e-4878-adb2-d1150643646b",
   "metadata": {},
   "source": [
    "Let's also retrieve the test data (used to validate the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d11e8d3e-73dd-4b80-8fdd-0676e510f331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:_list_feature_views will make breaking changes. Please use _list_batch_feature_views instead. _list_feature_views will behave like _list_all_feature_views in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using outcome_timestamp as the event timestamp. To specify a column explicitly, please name it event_timestamp.\n"
     ]
    }
   ],
   "source": [
    "# Pull the test data\n",
    "test_labels = pd.read_parquet(\"Feature_Store/data/test_y.parquet\")\n",
    "test_features = store.get_historical_features(\n",
    "    entity_df=test_labels,\n",
    "    features=[\n",
    "        \"data_test:duration\",\n",
    "        \"data_test:credit_amount\",\n",
    "        \"data_test:installment_commitment\",\n",
    "        \"data_test:checking_status_ord\",\n",
    "        \"data_test:residence_since\",\n",
    "        \"data_test:age\",\n",
    "        \"data_test:existing_credits\",\n",
    "        \"data_test:num_dependents\",\n",
    "        \"data_test:housing_ord\"\n",
    "    ]\n",
    ").to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b052f6b2-2a34-441d-8a5f-2aad4e4db022",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047ae8a7-26e7-447f-8465-8617aa73ad17",
   "metadata": {},
   "source": [
    "Now that we have pulled the feature data, we are ready to train the AI model. We train a random forest classifier with a few hyperparameters set. In particular, we have used the suggested class weights from the data set description that make a \"bad\" loan more important to identify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ff48f34-dbb6-4221-aefc-3c9b3f9da3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    criterion=\"entropy\",\n",
    "    max_depth=4,\n",
    "    min_samples_leaf=10,\n",
    "    class_weight={0:5, 1:1},\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d6ef38a-23b0-4056-a108-960495521164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={0: 5, 1: 1}, criterion=&#x27;entropy&#x27;,\n",
       "                       max_depth=4, min_samples_leaf=10, n_estimators=400,\n",
       "                       random_state=142)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight={0: 5, 1: 1}, criterion=&#x27;entropy&#x27;,\n",
       "                       max_depth=4, min_samples_leaf=10, n_estimators=400,\n",
       "                       random_state=142)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 5, 1: 1}, criterion='entropy',\n",
       "                       max_depth=4, min_samples_leaf=10, n_estimators=400,\n",
       "                       random_state=142)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove non-feature columns from context data\n",
    "feature_cols = [ \n",
    "    \"duration\", \"credit_amount\", \"installment_commitment\", \"checking_status_ord\",\n",
    "    \"residence_since\", \"age\", \"existing_credits\", \"num_dependents\", \"housing_ord\"\n",
    "]\n",
    "X = features.loc[:, feature_cols]\n",
    "y = features[\"class\"]\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c45c39-9d8e-4f76-aca5-9f0c1568d263",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef58d432-80ba-428f-b59f-621a9e53b331",
   "metadata": {},
   "source": [
    "Let's evaluate our base model performance. With credit risk, recall is going to be an important measure to look at. Let's view the performance on the training data, as well as on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c5472f6-2ddc-437d-8102-4d5bd2c9f39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.91      0.59       239\n",
      "         1.0       0.93      0.51      0.66       561\n",
      "\n",
      "    accuracy                           0.63       800\n",
      "   macro avg       0.69      0.71      0.62       800\n",
      "weighted avg       0.78      0.63      0.64       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate training set performance\n",
    "train_preds = model.predict(X)\n",
    "print(classification_report(y, train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c296bbd3-603e-4615-abbe-2689ebcf5d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      0.61      0.39        61\n",
      "         1.0       0.67      0.35      0.45       139\n",
      "\n",
      "    accuracy                           0.42       200\n",
      "   macro avg       0.48      0.48      0.42       200\n",
      "weighted avg       0.55      0.42      0.44       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate test data performance\n",
    "X_test = test_features.loc[:, feature_cols]\n",
    "y_test = test_labels[\"class\"]\n",
    "\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ffbdc-f0b3-4fb6-9575-5acd983082cf",
   "metadata": {},
   "source": [
    "The recall on the test set for bad loans (0 class) is 0.61, meaning that the model correctly identified close to 60% of the bad loans. However, the precision of 0.29 tells us that the model is also classifying many loans that were actually good as bad. Precision and recall are technical metrics. In order to truly assess the models value, we would need feedback from the business on the impact of misclassifications (for both good and bad loans).\n",
    "\n",
    "The difference in performance on the training vs. test data, tells us that the model is overfitting the data, and may have a trouble generalizing. Remember that this is just a quick baseline model. To improve further, we could do things like:\n",
    "- gather more data\n",
    "- engineer features\n",
    "- experiment with hyperparameter settings\n",
    "- experiment with other model types\n",
    "\n",
    "In fact, this is just a start. Creating AI models that meet business needs often requires a lot of guided experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0378d21a-d6db-42f9-851a-ce71f68c6802",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4450a328-f00c-4579-8e08-b2ebe5046961",
   "metadata": {},
   "source": [
    "The last thing we do is save our trained model, so that we can pick it up later in the serving environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da7a7906-d54f-4f2d-9803-6c82c86b28ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_model.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to a pickle file\n",
    "joblib.dump(model, \"rf_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299588b8-ab67-4155-97a9-770e8e4a7476",
   "metadata": {},
   "source": [
    "In the next notebook, [04_Credit_Risk_Model_Serving.ipynb](04_Credit_Risk_Model_Serving.ipynb), we will load the trained model and request predictions, with input features provided by the Feast online feature server."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

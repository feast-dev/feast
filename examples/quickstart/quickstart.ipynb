{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feast Codelab",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5JTeKfCVBZf"
      },
      "source": [
        "# Overview\n",
        "\n",
        "In this tutorial, we use feature stores to generate training data and power online model inference for a ride-sharing driver satisfaction prediction model. Feast addresses several common issues in this flow:\n",
        "1. **Training-serving skew and complex data joins:** Feature values often exist across multiple tables. Joining these datasets can be complicated, slow, and error-prone.\n",
        "  - Feast joins these tables with battle-tested logic that ensures *point-in-time* correctness so future feature values do not leak to models.\n",
        "  - **Upcoming*: Feast alerts users to offline / online skew with data quality monitoring. \n",
        "2. **Online feature availability:** At inference time, models often need access to features that aren't readily available and need to be precomputed from other datasources. \n",
        "  - Feast manages deployment to a variety of online stores (e.g. DynamoDB, Redis, Google Cloud Datastore) and ensures necessary features are consistently *available* and *freshly computed* at inference time.\n",
        "3. **Feature reusability and model versioning:** Different teams within an organization are often unable to reuse features across projects, resulting in duplicate feature creation logic. Models have data dependencies that need to be versioned, for example when running A/B tests on model versions.\n",
        "  - Feast enables discovery of and collaboration on previously used features and enables versioning of sets of features (via *feature services*). \n",
        "  - **Upcoming*: Feast enables feature transformation so users can re-use transformation logic across online / offline usecases and across models.\n",
        "\n",
        "We will:\n",
        "- Deploy a local feature store with a Parquet file offline store and Sqlite online store.\n",
        "- Build a training dataset using our time series features from our Parquet files.\n",
        "- Materialize feature values from the offline store into the online store in preparation for low latency serving.\n",
        "- Read the latest features from the online store for inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_Y997DzvOMI"
      },
      "source": [
        "## Step 1: Install Feast\n",
        "\n",
        "Install Feast (and Pygments for pretty printing) using pip:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXNMAAJKQPG5",
        "outputId": "b27420ac-c6ba-4d9f-cae8-51a2007b4189"
      },
      "source": [
        "%%sh\n",
        "pip install feast -U -q\n",
        "pip install Pygments -q\n",
        "echo \"Please restart your runtime now (Runtime -> Restart runtime). This ensures that the correct dependencies are loaded.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please restart your runtime now (Runtime -> Restart runtime). This ensures that the correct dependencies are loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "sOX_LwjaAhKz"
      },
      "source": [
        "**Reminder**: Please restart your runtime after installing Feast (Runtime -> Restart runtime). This ensures that the correct dependencies are loaded.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZetvs5xx4GP"
      },
      "source": [
        "## Step 2: Create a feature repository\n",
        "\n",
        "A feature repository is a directory that contains the configuration of the feature store and individual features. This configuration is written as code (Python/YAML) and it's highly recommended that teams track it centrally using git. See [Feature Repository](https://docs.feast.dev/reference/feature-repository) for a detailed explanation of feature repositories.\n",
        "\n",
        "The easiest way to create a new feature repository to use the `feast init` command. This creates a scaffolding with initial demo data.\n",
        "\n",
        "### Demo data scenario \n",
        "- We have surveyed some drivers for how satisfied they are with their experience in a ride-sharing app. \n",
        "- We want to generate predictions for driver satisfaction for the rest of the users so we can reach out to potentially dissatisfied users."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhirSkgUvYau",
        "outputId": "a2a5631e-1703-4957-b896-9c432851a261"
      },
      "source": [
        "!feast init feature_repo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feast is an open source project that collects anonymized error reporting and usage statistics. To opt out or learn more see https://docs.feast.dev/reference/usage\n",
            "\n",
            "Creating a new Feast repository in \u001b[1m\u001b[32m/content/feature_repo\u001b[0m.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdTASZPvyKCe"
      },
      "source": [
        "### Step 2a: Inspecting the feature repository\n",
        "\n",
        "Let's take a look at the demo repo itself. It breaks down into\n",
        "\n",
        "\n",
        "*   `data/` contains raw demo parquet data\n",
        "*   `example.py` contains demo feature definitions\n",
        "*   `feature_store.yaml` contains a demo setup configuring where data sources are\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jXuzt4ovzA3",
        "outputId": "1ef1bf42-2306-4cc0-c959-1ea2d62e3149"
      },
      "source": [
        "%cd feature_repo\n",
        "!ls -R"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/feature_repo\n",
            ".:\n",
            "data  example.py  feature_store.yaml\n",
            "\n",
            "./data:\n",
            "driver_stats.parquet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJk_WNsbeUP6"
      },
      "source": [
        "### Step 2b: Inspecting the project configuration\n",
        "Let's inspect the setup of the project in `feature_store.yaml`. The key line defining the overall architecture of the feature store is the **provider**. This defines where the raw data exists (for generating training data & feature values for serving), and where to materialize feature values to in the online store (for serving). \n",
        "\n",
        "Valid values for  `provider` in `feature_store.yaml` are:\n",
        "\n",
        "*   local: use file source / SQLite\n",
        "*   gcp: use BigQuery / Google Cloud Datastore\n",
        "*   aws: use Redshift / DynamoDB\n",
        "\n",
        "A custom setup (e.g. using the built-in support for Redis) can be made by following https://docs.feast.dev/v/master/how-to-guides/creating-a-custom-provider"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_YJ--uYdtcP",
        "outputId": "8d772619-aa4d-4cb4-e7e0-2ed45bc09a87"
      },
      "source": [
        "!pygmentize feature_store.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "project: feature_repo\n",
            "registry: data/registry.db\n",
            "provider: local\n",
            "online_store:\n",
            "    path: data/online_store.db\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnMlk4zshywp"
      },
      "source": [
        "### Inspecting the raw data\n",
        "\n",
        "The raw feature data we have in this demo is stored in a local parquet file. The dataset captures hourly stats of a driver in a ride-sharing app."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "sIF2lO59dwzi",
        "outputId": "3e7ff19e-1052-49a6-a889-de76cce61714"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.read_parquet(\"data/driver_stats.parquet\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>event_timestamp</th>\n",
              "      <th>driver_id</th>\n",
              "      <th>conv_rate</th>\n",
              "      <th>acc_rate</th>\n",
              "      <th>avg_daily_trips</th>\n",
              "      <th>created</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-08-08 16:00:00+00:00</td>\n",
              "      <td>1005</td>\n",
              "      <td>0.293061</td>\n",
              "      <td>0.001904</td>\n",
              "      <td>40</td>\n",
              "      <td>2021-08-23 16:25:16.962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-08-08 17:00:00+00:00</td>\n",
              "      <td>1005</td>\n",
              "      <td>0.411542</td>\n",
              "      <td>0.893139</td>\n",
              "      <td>722</td>\n",
              "      <td>2021-08-23 16:25:16.962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-08-08 18:00:00+00:00</td>\n",
              "      <td>1005</td>\n",
              "      <td>0.495635</td>\n",
              "      <td>0.202365</td>\n",
              "      <td>280</td>\n",
              "      <td>2021-08-23 16:25:16.962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-08-08 19:00:00+00:00</td>\n",
              "      <td>1005</td>\n",
              "      <td>0.890092</td>\n",
              "      <td>0.771689</td>\n",
              "      <td>88</td>\n",
              "      <td>2021-08-23 16:25:16.962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-08-08 20:00:00+00:00</td>\n",
              "      <td>1005</td>\n",
              "      <td>0.308211</td>\n",
              "      <td>0.126267</td>\n",
              "      <td>552</td>\n",
              "      <td>2021-08-23 16:25:16.962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802</th>\n",
              "      <td>2021-08-23 14:00:00+00:00</td>\n",
              "      <td>1001</td>\n",
              "      <td>0.251525</td>\n",
              "      <td>0.245729</td>\n",
              "      <td>98</td>\n",
              "      <td>2021-08-23 16:25:16.962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1803</th>\n",
              "      <td>2021-08-23 15:00:00+00:00</td>\n",
              "      <td>1001</td>\n",
              "      <td>0.469145</td>\n",
              "      <td>0.138416</td>\n",
              "      <td>606</td>\n",
              "      <td>2021-08-23 16:25:16.962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1804</th>\n",
              "      <td>2021-04-12 07:00:00+00:00</td>\n",
              "      <td>1001</td>\n",
              "      <td>0.897222</td>\n",
              "      <td>0.086379</td>\n",
              "      <td>314</td>\n",
              "      <td>2021-08-23 16:25:16.962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1805</th>\n",
              "      <td>2021-08-16 04:00:00+00:00</td>\n",
              "      <td>1003</td>\n",
              "      <td>0.298156</td>\n",
              "      <td>0.671153</td>\n",
              "      <td>162</td>\n",
              "      <td>2021-08-23 16:25:16.962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1806</th>\n",
              "      <td>2021-08-16 04:00:00+00:00</td>\n",
              "      <td>1003</td>\n",
              "      <td>0.298156</td>\n",
              "      <td>0.671153</td>\n",
              "      <td>162</td>\n",
              "      <td>2021-08-23 16:25:16.962</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1807 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               event_timestamp  ...                 created\n",
              "0    2021-08-08 16:00:00+00:00  ... 2021-08-23 16:25:16.962\n",
              "1    2021-08-08 17:00:00+00:00  ... 2021-08-23 16:25:16.962\n",
              "2    2021-08-08 18:00:00+00:00  ... 2021-08-23 16:25:16.962\n",
              "3    2021-08-08 19:00:00+00:00  ... 2021-08-23 16:25:16.962\n",
              "4    2021-08-08 20:00:00+00:00  ... 2021-08-23 16:25:16.962\n",
              "...                        ...  ...                     ...\n",
              "1802 2021-08-23 14:00:00+00:00  ... 2021-08-23 16:25:16.962\n",
              "1803 2021-08-23 15:00:00+00:00  ... 2021-08-23 16:25:16.962\n",
              "1804 2021-04-12 07:00:00+00:00  ... 2021-08-23 16:25:16.962\n",
              "1805 2021-08-16 04:00:00+00:00  ... 2021-08-23 16:25:16.962\n",
              "1806 2021-08-16 04:00:00+00:00  ... 2021-08-23 16:25:16.962\n",
              "\n",
              "[1807 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRL8-ubWzUFy"
      },
      "source": [
        "## Step 3: Register feature definitions and deploy your feature store\n",
        "\n",
        "`feast apply` scans python files in the current directory for feature/entity definitions and deploys infrastructure according to `feature_store.yaml`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NS4INL5n7ze"
      },
      "source": [
        "### Step 3a: Inspecting feature definitions\n",
        "Let's inspect what `example.py` looks like (the only python file in the repo):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPqXCoNpL0SX",
        "outputId": "a252e224-61da-48ee-92b8-1780def99244"
      },
      "source": [
        "!pygmentize -f terminal16m example.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;2;64;128;128m# This is an example feature definition file\u001b[39m\n",
            "\n",
            "\u001b[38;2;0;128;0;01mfrom\u001b[39;00m \u001b[38;2;0;0;255;01mgoogle.protobuf.duration_pb2\u001b[39;00m \u001b[38;2;0;128;0;01mimport\u001b[39;00m Duration\n",
            "\n",
            "\u001b[38;2;0;128;0;01mfrom\u001b[39;00m \u001b[38;2;0;0;255;01mfeast\u001b[39;00m \u001b[38;2;0;128;0;01mimport\u001b[39;00m Entity, Feature, FeatureView, FileSource, ValueType\n",
            "\n",
            "\u001b[38;2;64;128;128m# Read data from parquet files. Parquet is convenient for local development mode. For\u001b[39m\n",
            "\u001b[38;2;64;128;128m# production, you can use your favorite DWH, such as BigQuery. See Feast documentation\u001b[39m\n",
            "\u001b[38;2;64;128;128m# for more info.\u001b[39m\n",
            "driver_hourly_stats \u001b[38;2;102;102;102m=\u001b[39m FileSource(\n",
            "    path\u001b[38;2;102;102;102m=\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m\u001b[38;2;186;33;33m/content/feature_repo/data/driver_stats.parquet\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m,\n",
            "    event_timestamp_column\u001b[38;2;102;102;102m=\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m\u001b[38;2;186;33;33mevent_timestamp\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m,\n",
            "    created_timestamp_column\u001b[38;2;102;102;102m=\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m\u001b[38;2;186;33;33mcreated\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m,\n",
            ")\n",
            "\n",
            "\u001b[38;2;64;128;128m# Define an entity for the driver. You can think of entity as a primary key used to\u001b[39m\n",
            "\u001b[38;2;64;128;128m# fetch features.\u001b[39m\n",
            "driver \u001b[38;2;102;102;102m=\u001b[39m Entity(name\u001b[38;2;102;102;102m=\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m\u001b[38;2;186;33;33mdriver_id\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m, value_type\u001b[38;2;102;102;102m=\u001b[39mValueType\u001b[38;2;102;102;102m.\u001b[39mINT64, description\u001b[38;2;102;102;102m=\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m\u001b[38;2;186;33;33mdriver id\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m,)\n",
            "\n",
            "\u001b[38;2;64;128;128m# Our parquet files contain sample data that includes a driver_id column, timestamps and\u001b[39m\n",
            "\u001b[38;2;64;128;128m# three feature column. Here we define a Feature View that will allow us to serve this\u001b[39m\n",
            "\u001b[38;2;64;128;128m# data to our model online.\u001b[39m\n",
            "driver_hourly_stats_view \u001b[38;2;102;102;102m=\u001b[39m FeatureView(\n",
            "    name\u001b[38;2;102;102;102m=\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m\u001b[38;2;186;33;33mdriver_hourly_stats\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m,\n",
            "    entities\u001b[38;2;102;102;102m=\u001b[39m[\u001b[38;2;186;33;33m\"\u001b[39m\u001b[38;2;186;33;33mdriver_id\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m],\n",
            "    ttl\u001b[38;2;102;102;102m=\u001b[39mDuration(seconds\u001b[38;2;102;102;102m=\u001b[39m\u001b[38;2;102;102;102m86400\u001b[39m \u001b[38;2;102;102;102m*\u001b[39m \u001b[38;2;102;102;102m1\u001b[39m),\n",
            "    features\u001b[38;2;102;102;102m=\u001b[39m[\n",
            "        Feature(name\u001b[38;2;102;102;102m=\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m\u001b[38;2;186;33;33mconv_rate\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m, dtype\u001b[38;2;102;102;102m=\u001b[39mValueType\u001b[38;2;102;102;102m.\u001b[39mFLOAT),\n",
            "        Feature(name\u001b[38;2;102;102;102m=\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m\u001b[38;2;186;33;33macc_rate\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m, dtype\u001b[38;2;102;102;102m=\u001b[39mValueType\u001b[38;2;102;102;102m.\u001b[39mFLOAT),\n",
            "        Feature(name\u001b[38;2;102;102;102m=\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m\u001b[38;2;186;33;33mavg_daily_trips\u001b[39m\u001b[38;2;186;33;33m\"\u001b[39m, dtype\u001b[38;2;102;102;102m=\u001b[39mValueType\u001b[38;2;102;102;102m.\u001b[39mINT64),\n",
            "    ],\n",
            "    online\u001b[38;2;102;102;102m=\u001b[39m\u001b[38;2;0;128;0mTrue\u001b[39m,\n",
            "    batch_source\u001b[38;2;102;102;102m=\u001b[39mdriver_hourly_stats,\n",
            "    tags\u001b[38;2;102;102;102m=\u001b[39m{},\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im_cc5HdoDno"
      },
      "source": [
        "### Step 3b: Applying feature definitions\n",
        "Now we run `feast apply` to register the feature views and entities defined in `example.py`, and sets up SQLite online store tables. Note that we had previously specified SQLite as the online store in `feature_store.yaml` by specifying a `local` provider."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYKCKKrcxYZG",
        "outputId": "d36b3fb2-9292-4b43-f26a-5441c301c92d"
      },
      "source": [
        "!feast apply"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Registered entity \u001b[1m\u001b[32mdriver_id\u001b[0m\n",
            "Registered feature view \u001b[1m\u001b[32mdriver_hourly_stats\u001b[0m\n",
            "Deploying infrastructure for \u001b[1m\u001b[32mdriver_hourly_stats\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV7rtRQgzyf0"
      },
      "source": [
        "## Step 4: Generate training data\n",
        "\n",
        "To train a model, we need features and labels. Often, this label data is stored separately (e.g. you have one table storing user survey results and another set of tables with feature values). \n",
        "\n",
        "The user can query that table of labels with timestamps and pass that into Feast as an *entity dataframe* for training data generation. In many cases, Feast will also intelligently join relevant tables to create the relevant feature vectors.\n",
        "- Note that we include timestamps because want the features for the same driver at various timestamps to be used in a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6Fzia7YwBzz",
        "outputId": "250e9be1-2283-4d74-cf48-297b8ae0d23a"
      },
      "source": [
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "\n",
        "from feast import FeatureStore\n",
        "\n",
        "# The entity dataframe is the dataframe we want to enrich with feature values\n",
        "entity_df = pd.DataFrame.from_dict(\n",
        "    {\n",
        "        \"driver_id\": [1001, 1002, 1003],\n",
        "        \"label_driver_reported_satisfaction\": [1, 5, 3], \n",
        "        \"event_timestamp\": [\n",
        "            datetime.now() - timedelta(minutes=11),\n",
        "            datetime.now() - timedelta(minutes=36),\n",
        "            datetime.now() - timedelta(minutes=73),\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "store = FeatureStore(repo_path=\".\")\n",
        "\n",
        "training_df = store.get_historical_features(\n",
        "    entity_df=entity_df,\n",
        "    features=[\n",
        "        \"driver_hourly_stats:conv_rate\",\n",
        "        \"driver_hourly_stats:acc_rate\",\n",
        "        \"driver_hourly_stats:avg_daily_trips\",\n",
        "    ],\n",
        ").to_df()\n",
        "\n",
        "print(\"----- Feature schema -----\\n\")\n",
        "print(training_df.info())\n",
        "\n",
        "print()\n",
        "print(\"----- Example features -----\\n\")\n",
        "print(training_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Feature schema -----\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3 entries, 0 to 2\n",
            "Data columns (total 6 columns):\n",
            " #   Column                              Non-Null Count  Dtype              \n",
            "---  ------                              --------------  -----              \n",
            " 0   event_timestamp                     3 non-null      datetime64[ns, UTC]\n",
            " 1   driver_id                           3 non-null      int64              \n",
            " 2   label_driver_reported_satisfaction  3 non-null      int64              \n",
            " 3   conv_rate                           3 non-null      float32            \n",
            " 4   acc_rate                            3 non-null      float32            \n",
            " 5   avg_daily_trips                     3 non-null      int32              \n",
            "dtypes: datetime64[ns, UTC](1), float32(2), int32(1), int64(2)\n",
            "memory usage: 132.0 bytes\n",
            "None\n",
            "\n",
            "----- Example features -----\n",
            "\n",
            "                   event_timestamp  driver_id  ...  acc_rate  avg_daily_trips\n",
            "0 2021-08-23 15:12:55.489091+00:00       1003  ...  0.120588              938\n",
            "1 2021-08-23 15:49:55.489089+00:00       1002  ...  0.504881              635\n",
            "2 2021-08-23 16:14:55.489075+00:00       1001  ...  0.138416              606\n",
            "\n",
            "[3 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngl7HCtmz3hG"
      },
      "source": [
        "## Step 5: Load features into your online store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCXUpiQ_pmDk"
      },
      "source": [
        "### Step 5a: Using `feast materialize-incremental`\n",
        "\n",
        "We now serialize the latest values of features since the beginning of time to prepare for serving (note: `materialize-incremental` serializes all new features since the last `materialize` call)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z6QxIebAhK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efbb493a-89a2-41ce-b3b4-d0d05131a8ff"
      },
      "source": [
        "from datetime import datetime\n",
        "!feast materialize-incremental {datetime.now().isoformat()}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Materializing \u001b[1m\u001b[32m1\u001b[0m feature views to \u001b[1m\u001b[32m2021-08-23 16:25:46+00:00\u001b[0m into the \u001b[1m\u001b[32msqlite\u001b[0m online store.\n",
            "\n",
            "\u001b[1m\u001b[32mdriver_hourly_stats\u001b[0m from \u001b[1m\u001b[32m2021-08-22 16:25:47+00:00\u001b[0m to \u001b[1m\u001b[32m2021-08-23 16:25:46+00:00\u001b[0m:\n",
            "\r  0%|                                                                         | 0/5 [00:00<?, ?it/s]\r100%|████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 592.05it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7t12bhH4i9H"
      },
      "source": [
        "### Step 5b: Inspect materialized features\n",
        "\n",
        "Note that now there are `online_store.db` and `registry.db`, which store the materialized features and schema information, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVIgSYhI4cvR",
        "outputId": "c91be624-3646-413d-a9df-8d29e8c85bb1"
      },
      "source": [
        "print(\"--- Data directory ---\")\n",
        "!ls data\n",
        "\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "con = sqlite3.connect(\"data/online_store.db\")\n",
        "print(\"\\n--- Schema of online store ---\")\n",
        "print(\n",
        "    pd.read_sql_query(\n",
        "        \"SELECT * FROM feature_repo_driver_hourly_stats\", con).columns.tolist())\n",
        "con.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Data directory ---\n",
            "driver_stats.parquet  online_store.db  registry.db\n",
            "\n",
            "--- Schema of online store ---\n",
            "['entity_key', 'feature_name', 'value', 'event_ts', 'created_ts']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWcttaGalzAm"
      },
      "source": [
        "### Quick note on entity keys\n",
        "Note from the above command that the online store indexes by `entity_key`. \n",
        "\n",
        "[Entity keys](https://docs.feast.dev/getting-started/concepts/entity#entity-key) include a list of all entities needed (e.g. all relevant primary keys) to generate the feature vector. In this case, this is a serialized version of the `driver_id`. We use this later to fetch all features for a given driver at inference time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNecKOaI0J2Z"
      },
      "source": [
        "## Step 6: Fetching feature vectors for inference\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBFlKRsOAhK8"
      },
      "source": [
        "At inference time, we need to quickly read the latest feature values for different drivers (which otherwise might have existed only in batch sources) from the online feature store using `get_online_features()`. These feature vectors can then be fed to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-PUsUWUxoH9",
        "outputId": "78b12b00-4718-41c6-a33a-2d56f47bd05c"
      },
      "source": [
        "from pprint import pprint\n",
        "from feast import FeatureStore\n",
        "\n",
        "store = FeatureStore(repo_path=\".\")\n",
        "\n",
        "feature_vector = store.get_online_features(\n",
        "    features=[\n",
        "        \"driver_hourly_stats:conv_rate\",\n",
        "        \"driver_hourly_stats:acc_rate\",\n",
        "        \"driver_hourly_stats:avg_daily_trips\",\n",
        "    ],\n",
        "    entity_rows=[\n",
        "        {\"driver_id\": 1004},\n",
        "        {\"driver_id\": 1005},\n",
        "    ],\n",
        ").to_dict()\n",
        "\n",
        "pprint(feature_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'acc_rate': [0.5732735991477966, 0.7828438878059387],\n",
            " 'avg_daily_trips': [33, 984],\n",
            " 'conv_rate': [0.15498852729797363, 0.6263588070869446],\n",
            " 'driver_id': [1004, 1005]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg68gH2sy6H1"
      },
      "source": [
        "# Next steps\n",
        "\n",
        "- Read the [Concepts](https://docs.feast.dev/getting-started/concepts/) page to understand the Feast data model and architecture.\n",
        "- Check out our [Tutorials](https://docs.feast.dev/tutorials/tutorials-overview) section for more examples on how to use Feast.\n",
        "- Follow our [Running Feast with GCP/AWS](https://docs.feast.dev/how-to-guides/feast-gcp-aws) guide for a more in-depth tutorial on using Feast.\n",
        "- Join other Feast users and contributors in [Slack](https://slack.feast.dev/) and become part of the community!"
      ]
    }
  ]
}
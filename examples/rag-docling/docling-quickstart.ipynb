{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b19cb54f-e63f-4d9b-b7ff-d18a30635cd2",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this tutorial, we'll use Feast to inject documents and structured data (i.e., features) into the context of an LLM (Large Language Model) to power a RAG Application (Retrieval Augmented Generation).\n",
    "\n",
    "Feast solves several common issues in this flow:\n",
    "1. **Online retrieval:** At inference time, LLMs often need access to data that isn't readily \n",
    "   available and needs to be precomputed from other data sources.\n",
    "   * Feast manages deployment to a variety of online stores (e.g. Milvus, DynamoDB, Redis, Google Cloud Datastore) and \n",
    "     ensures necessary features are consistently _available_ and _freshly computed_ at inference time.\n",
    "2. **Vector Search:** Feast has built support for vector similarity search that is easily configured declaritively so users can focus on their application.\n",
    "3. **Richer structured data:** Along with vector search, users can query standard structured fields to inject into the LLM context for better user experiences.\n",
    "4. **Feature/Context and versioning:** Different teams within an organization are often unable to reuse \n",
    "   data across projects and services, resulting in duplicate application logic. Models have data dependencies that need \n",
    "   to be versioned, for example when running A/B tests on model/prompt versions.\n",
    "   * Feast enables discovery of and collaboration on previously used documents, features, and enables versioning of sets of \n",
    "     data.\n",
    "\n",
    "We will:\n",
    "1. Deploy a local feature store with a **Parquet file offline store** and **Sqlite online store**.\n",
    "2. Write/materialize the data (i.e., feature values) from the offline store (a parquet file) into the online store (Sqlite).\n",
    "3. Serve the features using the Feast SDK\n",
    "4. Inject the document into the LLM's context to answer questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "425cf2f7-70b5-423c-a4f2-f470d8638135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please restart your runtime now (Runtime -> Restart runtime). This ensures that the correct dependencies are loaded.\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pip install feast -U -q\n",
    "echo \"Please restart your runtime now (Runtime -> Restart runtime). This ensures that the correct dependencies are loaded.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db162bb9-e262-4958-990d-fd8f3f1f1249",
   "metadata": {},
   "source": [
    "**Reminder**: Please restart your runtime after installing Feast (Runtime -> Restart runtime). This ensures that the correct dependencies are loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25cf84f-c255-4bb3-a3d7-e5512c1ba10d",
   "metadata": {},
   "source": [
    "## Step 2: Create a feature repository\n",
    "\n",
    "A feature repository is a directory that contains the configuration of the feature store and individual features. This configuration is written as code (Python/YAML) and it's highly recommended that teams track it centrally using git. See [Feature Repository](https://docs.feast.dev/reference/feature-repository) for a detailed explanation of feature repositories.\n",
    "\n",
    "The easiest way to create a new feature repository to use the `feast init` command. For this demo, you **do not** need to initialize a feast repo.\n",
    "\n",
    "\n",
    "### Demo data scenario \n",
    "- We data from Wikipedia about states that we have embedded into sentence embeddings to be used for vector retrieval in a RAG application.\n",
    "- We want to generate predictions for driver satisfaction for the rest of the users so we can reach out to potentially dissatisfied users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c07166a0-ff77-4bc7-b159-feb8f43aa3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c969b62f-4f58-49ed-ae23-ace1916de0c0",
   "metadata": {},
   "source": [
    "### Step 2a: Inspecting the feature repository\n",
    "\n",
    "Let's take a look at the demo repo itself. It breaks down into\n",
    "\n",
    "\n",
    "* `data/` contains raw demo parquet data\n",
    "* `example_repo.py` contains demo feature definitions\n",
    "* `feature_store.yaml` contains a demo setup configuring where data sources are\n",
    "* `test_workflow.py` showcases how to run all key Feast commands, including defining, retrieving, and pushing features.\n",
    "   * You can run this with `python test_workflow.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d531836-5981-4a34-9367-51b09af18a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/farceo/dev/feast/examples/rag-docling/feature_repo\n",
      "__init__.py        \u001b[1m\u001b[36mdata\u001b[m\u001b[m               feature_store.yaml\n",
      "\u001b[1m\u001b[36m__pycache__\u001b[m\u001b[m        example_repo.py    test_workflow.py\n",
      "\n",
      "./__pycache__:\n",
      "example_repo.cpython-310.pyc example_repo.cpython-311.pyc\n",
      "\n",
      "./data:\n",
      "Untitled.ipynb                registry.db\n",
      "docling_samples.parquet       small.pdf\n",
      "metadata_samples.parquet      smallest-possible-pdf-2.0.pdf\n",
      "online_store.db               tmp.ipynb\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/farceo/dev/feast/examples/rag-docling/feature_repo/\n",
    "!ls -R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14a8073-5030-4d35-9c96-f5360aeaf39f",
   "metadata": {},
   "source": [
    "### Step 2b: Inspecting the project configuration\n",
    "Let's inspect the setup of the project in `feature_store.yaml`. \n",
    "\n",
    "The key line defining the overall architecture of the feature store is the **provider**. \n",
    "\n",
    "The provider value sets default offline and online stores. \n",
    "* The offline store provides the compute layer to process historical data (for generating training data & feature \n",
    "  values for serving). \n",
    "* The online store is a low latency store of the latest feature values (for powering real-time inference).\n",
    "\n",
    "Valid values for `provider` in `feature_store.yaml` are:\n",
    "\n",
    "* local: use file source with Milvus Lite\n",
    "* gcp: use BigQuery/Snowflake with Google Cloud Datastore/Redis\n",
    "* aws: use Redshift/Snowflake with DynamoDB/Redis\n",
    "\n",
    "Note that there are many other offline / online stores Feast works with, including Azure, Hive, Trino, and PostgreSQL via community plugins. See https://docs.feast.dev/roadmap for all supported connectors.\n",
    "\n",
    "A custom setup can also be made by following [Customizing Feast](https://docs.feast.dev/v/master/how-to-guides/customizing-feast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c830ef-f5a4-4867-ad5c-87e709df7057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;0;128;0;01mproject\u001b[39;00m:\u001b[38;2;187;187;187m \u001b[39mrag\n",
      "\u001b[38;2;0;128;0;01mprovider\u001b[39;00m:\u001b[38;2;187;187;187m \u001b[39mlocal\n",
      "\u001b[38;2;0;128;0;01mregistry\u001b[39;00m:\u001b[38;2;187;187;187m \u001b[39mdata/registry.db\n",
      "\u001b[38;2;0;128;0;01monline_store\u001b[39;00m:\n",
      "\u001b[38;2;187;187;187m  \u001b[39m\u001b[38;2;0;128;0;01mtype\u001b[39;00m:\u001b[38;2;187;187;187m \u001b[39msqlite\n",
      "\u001b[38;2;187;187;187m  \u001b[39m\u001b[38;2;0;128;0;01mpath\u001b[39;00m:\u001b[38;2;187;187;187m \u001b[39mdata/online_store.db\n",
      "\u001b[38;2;187;187;187m  \u001b[39m\u001b[38;2;0;128;0;01mvector_enabled\u001b[39;00m:\u001b[38;2;187;187;187m \u001b[39mtrue\n",
      "\u001b[38;2;187;187;187m  \u001b[39m\u001b[38;2;0;128;0;01mvector_len\u001b[39;00m:\u001b[38;2;187;187;187m \u001b[39m384\n",
      "\u001b[38;2;187;187;187m  \u001b[39m\u001b[38;2;61;123;123;03m# type: milvus\u001b[39;00m\n",
      "\u001b[38;2;187;187;187m  \u001b[39m\u001b[38;2;61;123;123;03m# path: data/online_store.db\u001b[39;00m\n",
      "\u001b[38;2;187;187;187m  \u001b[39m\u001b[38;2;61;123;123;03m# embedding_dim: 384\u001b[39;00m\n",
      "\u001b[38;2;187;187;187m  \u001b[39m\u001b[38;2;61;123;123;03m# index_type: \"IVF_FLAT\"\u001b[39;00m\n",
      "\n",
      "\n",
      "\u001b[38;2;0;128;0;01moffline_store\u001b[39;00m:\n",
      "\u001b[38;2;187;187;187m  \u001b[39m\u001b[38;2;0;128;0;01mtype\u001b[39;00m:\u001b[38;2;187;187;187m \u001b[39mfile\n",
      "\u001b[38;2;0;128;0;01mentity_key_serialization_version\u001b[39;00m:\u001b[38;2;187;187;187m \u001b[39m3\n",
      "\u001b[38;2;61;123;123;03m# By default, no_auth for authentication and authorization, other possible values kubernetes and oidc. Refer the documentation for more details.\u001b[39;00m\n",
      "\u001b[38;2;0;128;0;01mauth\u001b[39;00m:\n",
      "\u001b[38;2;187;187;187m    \u001b[39m\u001b[38;2;0;128;0;01mtype\u001b[39;00m:\u001b[38;2;187;187;187m \u001b[39mno_auth\n"
     ]
    }
   ],
   "source": [
    "!pygmentize feature_store.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce80d1a-05d3-434d-bd1e-1ade8abd1f9f",
   "metadata": {},
   "source": [
    "### Inspecting the raw data\n",
    "\n",
    "The raw feature data we have in this demo is stored in a local parquet file. The dataset Wikipedia summaries of diferent cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8d9d8d5-381b-4da7-acf6-6eaaf577a7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>raw_chunk_markdown</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc-1</td>\n",
       "      <td>chunk-1</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>Ahmed Nassar, Nikolaos Livathinos, Maksym Lysa...</td>\n",
       "      <td>[-0.056879762560129166, 0.01667858101427555, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc-1</td>\n",
       "      <td>chunk-2</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\nTables organize valuab...</td>\n",
       "      <td>[0.050771258771419525, -0.0055733839981257915,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc-1</td>\n",
       "      <td>chunk-3</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\ncomplex column/row-hea...</td>\n",
       "      <td>[-0.05088765174150467, 0.05101901665329933, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc-1</td>\n",
       "      <td>chunk-4</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\nmodel. The latter impr...</td>\n",
       "      <td>[0.011835305020213127, -0.09409898519515991, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc-1</td>\n",
       "      <td>chunk-5</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\nwe can obtain the cont...</td>\n",
       "      <td>[-0.0068757119588553905, 0.006624480709433556,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  document_id chunk_id     file_name  \\\n",
       "0       doc-1  chunk-1  2203.01017v2   \n",
       "1       doc-1  chunk-2  2203.01017v2   \n",
       "2       doc-1  chunk-3  2203.01017v2   \n",
       "3       doc-1  chunk-4  2203.01017v2   \n",
       "4       doc-1  chunk-5  2203.01017v2   \n",
       "\n",
       "                                  raw_chunk_markdown  \\\n",
       "0  Ahmed Nassar, Nikolaos Livathinos, Maksym Lysa...   \n",
       "1  a. Picture of a table:\\nTables organize valuab...   \n",
       "2  a. Picture of a table:\\ncomplex column/row-hea...   \n",
       "3  a. Picture of a table:\\nmodel. The latter impr...   \n",
       "4  a. Picture of a table:\\nwe can obtain the cont...   \n",
       "\n",
       "                                              vector  \n",
       "0  [-0.056879762560129166, 0.01667858101427555, -...  \n",
       "1  [0.050771258771419525, -0.0055733839981257915,...  \n",
       "2  [-0.05088765174150467, 0.05101901665329933, -0...  \n",
       "3  [0.011835305020213127, -0.09409898519515991, 0...  \n",
       "4  [-0.0068757119588553905, 0.006624480709433556,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "788a27ff-16a4-4b23-8c1c-ba27fd918aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding length = 384\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_parquet(\"./data/docling_samples.parquet\")\n",
    "mdf = pd.read_parquet(\"./data/metadata_samples.parquet\")\n",
    "df['chunk_embedding'] = df['vector'].apply(lambda x: x.tolist())\n",
    "embedding_length = len(df['vector'][0])\n",
    "print(f'embedding length = {embedding_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ada1bf0a-8b1a-4821-becd-488abeb4d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created'] = pd.Timestamp.now()\n",
    "mdf['created'] = pd.Timestamp.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "058d5634-0ac2-4e9a-a677-f0869de61f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>raw_chunk_markdown</th>\n",
       "      <th>vector</th>\n",
       "      <th>chunk_embedding</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc-1</td>\n",
       "      <td>chunk-1</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>Ahmed Nassar, Nikolaos Livathinos, Maksym Lysa...</td>\n",
       "      <td>[-0.056879762560129166, 0.01667858101427555, -...</td>\n",
       "      <td>[-0.056879762560129166, 0.01667858101427555, -...</td>\n",
       "      <td>2025-03-26 22:50:32.803496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc-1</td>\n",
       "      <td>chunk-2</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\nTables organize valuab...</td>\n",
       "      <td>[0.050771258771419525, -0.0055733839981257915,...</td>\n",
       "      <td>[0.050771258771419525, -0.0055733839981257915,...</td>\n",
       "      <td>2025-03-26 22:50:32.803496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc-1</td>\n",
       "      <td>chunk-3</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\ncomplex column/row-hea...</td>\n",
       "      <td>[-0.05088765174150467, 0.05101901665329933, -0...</td>\n",
       "      <td>[-0.05088765174150467, 0.05101901665329933, -0...</td>\n",
       "      <td>2025-03-26 22:50:32.803496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc-1</td>\n",
       "      <td>chunk-4</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\nmodel. The latter impr...</td>\n",
       "      <td>[0.011835305020213127, -0.09409898519515991, 0...</td>\n",
       "      <td>[0.011835305020213127, -0.09409898519515991, 0...</td>\n",
       "      <td>2025-03-26 22:50:32.803496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc-1</td>\n",
       "      <td>chunk-5</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\nwe can obtain the cont...</td>\n",
       "      <td>[-0.0068757119588553905, 0.006624480709433556,...</td>\n",
       "      <td>[-0.0068757119588553905, 0.006624480709433556,...</td>\n",
       "      <td>2025-03-26 22:50:32.803496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  document_id chunk_id     file_name  \\\n",
       "0       doc-1  chunk-1  2203.01017v2   \n",
       "1       doc-1  chunk-2  2203.01017v2   \n",
       "2       doc-1  chunk-3  2203.01017v2   \n",
       "3       doc-1  chunk-4  2203.01017v2   \n",
       "4       doc-1  chunk-5  2203.01017v2   \n",
       "\n",
       "                                  raw_chunk_markdown  \\\n",
       "0  Ahmed Nassar, Nikolaos Livathinos, Maksym Lysa...   \n",
       "1  a. Picture of a table:\\nTables organize valuab...   \n",
       "2  a. Picture of a table:\\ncomplex column/row-hea...   \n",
       "3  a. Picture of a table:\\nmodel. The latter impr...   \n",
       "4  a. Picture of a table:\\nwe can obtain the cont...   \n",
       "\n",
       "                                              vector  \\\n",
       "0  [-0.056879762560129166, 0.01667858101427555, -...   \n",
       "1  [0.050771258771419525, -0.0055733839981257915,...   \n",
       "2  [-0.05088765174150467, 0.05101901665329933, -0...   \n",
       "3  [0.011835305020213127, -0.09409898519515991, 0...   \n",
       "4  [-0.0068757119588553905, 0.006624480709433556,...   \n",
       "\n",
       "                                     chunk_embedding  \\\n",
       "0  [-0.056879762560129166, 0.01667858101427555, -...   \n",
       "1  [0.050771258771419525, -0.0055733839981257915,...   \n",
       "2  [-0.05088765174150467, 0.05101901665329933, -0...   \n",
       "3  [0.011835305020213127, -0.09409898519515991, 0...   \n",
       "4  [-0.0068757119588553905, 0.006624480709433556,...   \n",
       "\n",
       "                     created  \n",
       "0 2025-03-26 22:50:32.803496  \n",
       "1 2025-03-26 22:50:32.803496  \n",
       "2 2025-03-26 22:50:32.803496  \n",
       "3 2025-03-26 22:50:32.803496  \n",
       "4 2025-03-26 22:50:32.803496  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e36b538d-21d2-4770-b5d0-667aaa9fe1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>full_document_markdown</th>\n",
       "      <th>pdf_bytes</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc-1</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>## TableFormer: Table Structure Understanding ...</td>\n",
       "      <td>b'%PDF-1.5\\n%\\x8f\\n5 0 obj\\n&lt;&lt; /Type /XObject ...</td>\n",
       "      <td>2025-03-26 22:50:32.804817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc-3</td>\n",
       "      <td>2305.03393v1-pg9</td>\n",
       "      <td>order to compute the TED score. Inference timi...</td>\n",
       "      <td>b'%PDF-1.3\\n%\\xc4\\xe5\\xf2\\xe5\\xeb\\xa7\\xf3\\xa0\\...</td>\n",
       "      <td>2025-03-26 22:50:32.804817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc-2</td>\n",
       "      <td>2305.03393v1</td>\n",
       "      <td>## Optimized Table Tokenization for Table Stru...</td>\n",
       "      <td>b'%PDF-1.5\\n%\\x8f\\n74 0 obj\\n&lt;&lt; /Filter /Flate...</td>\n",
       "      <td>2025-03-26 22:50:32.804817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc-4</td>\n",
       "      <td>amt_handbook_sample</td>\n",
       "      <td>pulleys, provided the inner race of the bearin...</td>\n",
       "      <td>b'%PDF-1.6\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n875 0 obj\\r&lt;&lt;...</td>\n",
       "      <td>2025-03-26 22:50:32.804817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc-5</td>\n",
       "      <td>code_and_formula</td>\n",
       "      <td>## JavaScript Code Example\\n\\nLorem ipsum dolo...</td>\n",
       "      <td>b'%PDF-1.5\\n%\\xbf\\xf7\\xa2\\xfe\\n3 0 obj\\n&lt;&lt; /Li...</td>\n",
       "      <td>2025-03-26 22:50:32.804817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  document_id            file_name  \\\n",
       "0       doc-1         2203.01017v2   \n",
       "1       doc-3     2305.03393v1-pg9   \n",
       "2       doc-2         2305.03393v1   \n",
       "3       doc-4  amt_handbook_sample   \n",
       "4       doc-5     code_and_formula   \n",
       "\n",
       "                              full_document_markdown  \\\n",
       "0  ## TableFormer: Table Structure Understanding ...   \n",
       "1  order to compute the TED score. Inference timi...   \n",
       "2  ## Optimized Table Tokenization for Table Stru...   \n",
       "3  pulleys, provided the inner race of the bearin...   \n",
       "4  ## JavaScript Code Example\\n\\nLorem ipsum dolo...   \n",
       "\n",
       "                                           pdf_bytes  \\\n",
       "0  b'%PDF-1.5\\n%\\x8f\\n5 0 obj\\n<< /Type /XObject ...   \n",
       "1  b'%PDF-1.3\\n%\\xc4\\xe5\\xf2\\xe5\\xeb\\xa7\\xf3\\xa0\\...   \n",
       "2  b'%PDF-1.5\\n%\\x8f\\n74 0 obj\\n<< /Filter /Flate...   \n",
       "3  b'%PDF-1.6\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n875 0 obj\\r<<...   \n",
       "4  b'%PDF-1.5\\n%\\xbf\\xf7\\xa2\\xfe\\n3 0 obj\\n<< /Li...   \n",
       "\n",
       "                     created  \n",
       "0 2025-03-26 22:50:32.804817  \n",
       "1 2025-03-26 22:50:32.804817  \n",
       "2 2025-03-26 22:50:32.804817  \n",
       "3 2025-03-26 22:50:32.804817  \n",
       "4 2025-03-26 22:50:32.804817  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec07d38d-d0ff-4dc3-b041-3bf24de9e7e3",
   "metadata": {},
   "source": [
    "## Step 3: Register feature definitions and deploy your feature store\n",
    "\n",
    "`feast apply` scans python files in the current directory for feature/entity definitions and deploys infrastructure according to `feature_store.yaml`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79409ca9-7552-4aa5-b95b-29f836a0d3a5",
   "metadata": {},
   "source": [
    "### Step 3a: Inspecting feature definitions\n",
    "Let's inspect what `example_repo.py` looks like:\n",
    "\n",
    "```python\n",
    "from datetime import timedelta\n",
    "\n",
    "from feast import (\n",
    "    FeatureView,\n",
    "    Field,\n",
    "    FileSource,\n",
    ")\n",
    "from feast.data_format import ParquetFormat\n",
    "from feast.types import Float32, Array, String, ValueType\n",
    "from feast import Entity\n",
    "\n",
    "chunk = Entity(\n",
    "    name=\"chunk_id\",\n",
    "    description=\"Chunk ID\",\n",
    "    value_type=ValueType.STRING,\n",
    ")\n",
    "\n",
    "parquet_file_path = \"./data/docling_samples.parquet\"\n",
    "\n",
    "source = FileSource(\n",
    "    file_format=ParquetFormat(),\n",
    "    path=parquet_file_path,\n",
    "    timestamp_field=\"created\",\n",
    ")\n",
    "\n",
    "city_embeddings_feature_view = FeatureView(\n",
    "    name=\"docling_fv\",\n",
    "    entities=[chunk],\n",
    "    schema=[\n",
    "        Field(name=\"file_name\", dtype=String),\n",
    "        Field(name=\"full_document_markdown\", dtype=String),\n",
    "        Field(name=\"raw_chunk_markdown\", dtype=String),\n",
    "        Field(\n",
    "            name=\"vector\",\n",
    "            dtype=Array(Float32),\n",
    "            vector_index=True,\n",
    "            vector_search_metric=\"COSINE\",\n",
    "        ),\n",
    "        Field(name=\"bytes\", dtype=String),\n",
    "        Field(name=\"chunk_id\", dtype=String),\n",
    "    ],\n",
    "    source=source,\n",
    "    ttl=timedelta(hours=2),\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76634929-c84a-4301-93d3-88292335bde0",
   "metadata": {},
   "source": [
    "### Step 3b: Applying feature definitions\n",
    "Now we run `feast apply` to register the feature views and entities defined in `example_repo.py`, and sets up SQLite online store tables. Note that we had previously specified SQLite as the online store in `feature_store.yaml` by specifying a `local` provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63454dea-9d55-4188-b048-8b943fe80e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -rf .ipynb_checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "837e1530-e863-4e5f-b206-b6b4b3ca2aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"vector_enabled\" in \"SqliteOnlineStoreConfig\" shadows an attribute in parent \"VectorStoreConfig\"\n",
      "  warnings.warn(\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"vector_len\" in \"SqliteOnlineStoreConfig\" shadows an attribute in parent \"VectorStoreConfig\"\n",
      "  warnings.warn(\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling_core/types/doc/document.py:3272: DeprecationWarning: deprecated\n",
      "  if not d.validate_tree(d.body) or not d.validate_tree(d.furniture):\n",
      "No project found in the repository. Using project name rag defined in feature_store.yaml\n",
      "Applying changes for project rag\n",
      "/Users/farceo/dev/feast/sdk/python/feast/feature_store.py:581: RuntimeWarning: On demand feature view is an experimental feature. This API is stable, but the functionality does not scale well for offline retrieval\n",
      "  warnings.warn(\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling/pipeline/standard_pdf_pipeline.py:76: DeprecationWarning: Field `generate_table_images` is deprecated. To obtain table images, set `PdfPipelineOptions.generate_page_images = True` before conversion and then use the `TableItem.get_image` function.\n",
      "  or self.pipeline_options.generate_table_images\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling_core/types/doc/document.py:3272: DeprecationWarning: deprecated\n",
      "  if not d.validate_tree(d.body) or not d.validate_tree(d.furniture):\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling/pipeline/standard_pdf_pipeline.py:268: DeprecationWarning: Field `generate_table_images` is deprecated. To obtain table images, set `PdfPipelineOptions.generate_page_images = True` before conversion and then use the `TableItem.get_image` function.\n",
      "  or self.pipeline_options.generate_table_images\n",
      "Updated feature view \u001b[1m\u001b[33mdocling_feature_view\u001b[0m\n",
      "\tfeatures: \u001b[1m\u001b[33m[name: \"file_name\"\n",
      "value_type: STRING\n",
      ", name: \"raw_chunk_markdown\"\n",
      "value_type: STRING\n",
      ", name: \"vector\"\n",
      "value_type: DOUBLE_LIST\n",
      "vector_index: true\n",
      "vector_search_metric: \"COSINE\"\n",
      "]\u001b[0m -> \u001b[1m\u001b[92m[name: \"file_name\"\n",
      "value_type: STRING\n",
      ", name: \"raw_chunk_markdown\"\n",
      "value_type: STRING\n",
      ", name: \"vector\"\n",
      "value_type: FLOAT_LIST\n",
      "vector_index: true\n",
      "vector_search_metric: \"COSINE\"\n",
      "]\u001b[0m\n",
      "Updated on demand feature view \u001b[1m\u001b[33mdocling_transform_docs\u001b[0m\n",
      "\tfeatures: \u001b[1m\u001b[33m[name: \"document_id\"\n",
      "value_type: STRING\n",
      ", name: \"chunk_id\"\n",
      "value_type: STRING\n",
      ", name: \"chunk_text\"\n",
      "value_type: STRING\n",
      ", name: \"vector\"\n",
      "value_type: DOUBLE_LIST\n",
      "]\u001b[0m -> \u001b[1m\u001b[92m[name: \"document_id\"\n",
      "value_type: STRING\n",
      ", name: \"chunk_id\"\n",
      "value_type: STRING\n",
      ", name: \"chunk_text\"\n",
      "value_type: STRING\n",
      ", name: \"vector\"\n",
      "value_type: FLOAT_LIST\n",
      "]\u001b[0m\n",
      "\tfeature_transformation.body_text: \u001b[1m\u001b[33m@on_demand_feature_view(\n",
      "    sources=[input_request_pdf],\n",
      "    schema=[\n",
      "        Field(name=\"document_id\", dtype=String),\n",
      "        Field(name=\"chunk_id\", dtype=String),\n",
      "        Field(name=\"chunk_text\", dtype=String),\n",
      "        Field(\n",
      "            name=\"vector\", \n",
      "            dtype=Array(Float64), \n",
      "            vector_index=False\n",
      "        ),\n",
      "    ],\n",
      "    mode=\"python\",\n",
      "    singleton=True,\n",
      "    write_to_online_store=True,\n",
      ")\n",
      "def docling_transform_docs(inputs: Dict[str, Any]):\n",
      "    document_ids, chunks, embeddings, chunk_ids = [], [], [], []\n",
      "    buf = io.BytesIO(\n",
      "        inputs[\"pdf_bytes\"],\n",
      "    )\n",
      "    source = DocumentStream(name=inputs[\"file_name\"], stream=buf)\n",
      "    converter = DocumentConverter()\n",
      "    result = converter.convert(source)\n",
      "    for i, chunk in enumerate(chunker.chunk(dl_doc=result.document)):\n",
      "        raw_chunk = chunker.serialize(chunk=chunk)\n",
      "        # embedding = embed_chunk(raw_chunk).get(\"query_embedding\", [])\n",
      "        embedding = embed_text(raw_chunk)\n",
      "        chunk_id = f\"chunk-{i}\"\n",
      "        document_ids.append(inputs[\"document_id\"])\n",
      "        chunks.append(raw_chunk)\n",
      "        chunk_ids.append(chunk_id)\n",
      "        embeddings.append(embedding)\n",
      "    return {\n",
      "        \"document_id\": document_ids,\n",
      "        \"chunk_id\": chunk_ids,\n",
      "        \"vector\": embeddings,\n",
      "        \"chunk_text\": chunks,\n",
      "    }\n",
      "\u001b[0m -> \u001b[1m\u001b[92m@on_demand_feature_view(\n",
      "    sources=[input_request_pdf],\n",
      "    schema=[\n",
      "        Field(name=\"document_id\", dtype=String),\n",
      "        Field(name=\"chunk_id\", dtype=String),\n",
      "        Field(name=\"chunk_text\", dtype=String),\n",
      "        Field(\n",
      "            name=\"vector\", \n",
      "            dtype=Array(Float32), \n",
      "            vector_index=False\n",
      "        ),\n",
      "    ],\n",
      "    mode=\"python\",\n",
      "    singleton=True,\n",
      "    write_to_online_store=True,\n",
      ")\n",
      "def docling_transform_docs(inputs: Dict[str, Any]):\n",
      "    document_ids, chunks, embeddings, chunk_ids = [], [], [], []\n",
      "    buf = io.BytesIO(\n",
      "        inputs[\"pdf_bytes\"],\n",
      "    )\n",
      "    source = DocumentStream(name=inputs[\"file_name\"], stream=buf)\n",
      "    converter = DocumentConverter()\n",
      "    result = converter.convert(source)\n",
      "    for i, chunk in enumerate(chunker.chunk(dl_doc=result.document)):\n",
      "        raw_chunk = chunker.serialize(chunk=chunk)\n",
      "        # embedding = embed_chunk(raw_chunk).get(\"query_embedding\", [])\n",
      "        embedding = embed_text(raw_chunk)\n",
      "        chunk_id = f\"chunk-{i}\"\n",
      "        document_ids.append(inputs[\"document_id\"])\n",
      "        chunks.append(raw_chunk)\n",
      "        chunk_ids.append(chunk_id)\n",
      "        embeddings.append(embedding)\n",
      "    return {\n",
      "        \"document_id\": document_ids,\n",
      "        \"chunk_id\": chunk_ids,\n",
      "        \"vector\": embeddings,\n",
      "        \"chunk_text\": chunks,\n",
      "    }\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[94mNo changes to infrastructure\n"
     ]
    }
   ],
   "source": [
    "! feast apply "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7654cc-865c-4bb4-8c0f-d3086c5d9f7e",
   "metadata": {},
   "source": [
    "## Step 5: Load features into your online store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34ded931-3de0-4951-aead-1e8ca1679cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from feast import FeatureStore\n",
    "\n",
    "store = FeatureStore(repo_path=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c784d77-e96c-455c-9f1f-9183bab58d72",
   "metadata": {},
   "source": [
    "### Step 5a: Using `write_to_online_store`\n",
    "\n",
    "We now serialize the latest values of features since the beginning of time to prepare for serving. Note, `materialize_incremental` serializes all new features since the last `materialize` call, or since the time provided minus the `ttl` timedelta. In this case, this will be `CURRENT_TIME - 1 day` (`ttl` was set on the `FeatureView` instances in [feature_repo/feature_repo/example_repo.py](feature_repo/feature_repo/example_repo.py)). \n",
    "\n",
    "```bash\n",
    "CURRENT_TIME=$(date -u +\"%Y-%m-%dT%H:%M:%S\")\n",
    "feast materialize-incremental $CURRENT_TIME\n",
    "```\n",
    "\n",
    "An alternative to using the CLI command is to use Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ebfcb4a-c275-421d-bfb4-347b821ea15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>raw_chunk_markdown</th>\n",
       "      <th>vector</th>\n",
       "      <th>chunk_embedding</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc-1</td>\n",
       "      <td>chunk-1</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>Ahmed Nassar, Nikolaos Livathinos, Maksym Lysa...</td>\n",
       "      <td>[-0.056879762560129166, 0.01667858101427555, -...</td>\n",
       "      <td>[-0.056879762560129166, 0.01667858101427555, -...</td>\n",
       "      <td>2025-03-26 22:50:32.803496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc-1</td>\n",
       "      <td>chunk-2</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\nTables organize valuab...</td>\n",
       "      <td>[0.050771258771419525, -0.0055733839981257915,...</td>\n",
       "      <td>[0.050771258771419525, -0.0055733839981257915,...</td>\n",
       "      <td>2025-03-26 22:50:32.803496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc-1</td>\n",
       "      <td>chunk-3</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\ncomplex column/row-hea...</td>\n",
       "      <td>[-0.05088765174150467, 0.05101901665329933, -0...</td>\n",
       "      <td>[-0.05088765174150467, 0.05101901665329933, -0...</td>\n",
       "      <td>2025-03-26 22:50:32.803496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc-1</td>\n",
       "      <td>chunk-4</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\nmodel. The latter impr...</td>\n",
       "      <td>[0.011835305020213127, -0.09409898519515991, 0...</td>\n",
       "      <td>[0.011835305020213127, -0.09409898519515991, 0...</td>\n",
       "      <td>2025-03-26 22:50:32.803496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc-1</td>\n",
       "      <td>chunk-5</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\nwe can obtain the cont...</td>\n",
       "      <td>[-0.0068757119588553905, 0.006624480709433556,...</td>\n",
       "      <td>[-0.0068757119588553905, 0.006624480709433556,...</td>\n",
       "      <td>2025-03-26 22:50:32.803496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  document_id chunk_id     file_name  \\\n",
       "0       doc-1  chunk-1  2203.01017v2   \n",
       "1       doc-1  chunk-2  2203.01017v2   \n",
       "2       doc-1  chunk-3  2203.01017v2   \n",
       "3       doc-1  chunk-4  2203.01017v2   \n",
       "4       doc-1  chunk-5  2203.01017v2   \n",
       "\n",
       "                                  raw_chunk_markdown  \\\n",
       "0  Ahmed Nassar, Nikolaos Livathinos, Maksym Lysa...   \n",
       "1  a. Picture of a table:\\nTables organize valuab...   \n",
       "2  a. Picture of a table:\\ncomplex column/row-hea...   \n",
       "3  a. Picture of a table:\\nmodel. The latter impr...   \n",
       "4  a. Picture of a table:\\nwe can obtain the cont...   \n",
       "\n",
       "                                              vector  \\\n",
       "0  [-0.056879762560129166, 0.01667858101427555, -...   \n",
       "1  [0.050771258771419525, -0.0055733839981257915,...   \n",
       "2  [-0.05088765174150467, 0.05101901665329933, -0...   \n",
       "3  [0.011835305020213127, -0.09409898519515991, 0...   \n",
       "4  [-0.0068757119588553905, 0.006624480709433556,...   \n",
       "\n",
       "                                     chunk_embedding  \\\n",
       "0  [-0.056879762560129166, 0.01667858101427555, -...   \n",
       "1  [0.050771258771419525, -0.0055733839981257915,...   \n",
       "2  [-0.05088765174150467, 0.05101901665329933, -0...   \n",
       "3  [0.011835305020213127, -0.09409898519515991, 0...   \n",
       "4  [-0.0068757119588553905, 0.006624480709433556,...   \n",
       "\n",
       "                     created  \n",
       "0 2025-03-26 22:50:32.803496  \n",
       "1 2025-03-26 22:50:32.803496  \n",
       "2 2025-03-26 22:50:32.803496  \n",
       "3 2025-03-26 22:50:32.803496  \n",
       "4 2025-03-26 22:50:32.803496  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2655725-5cc4-4f07-ade4-dc5e705eed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.write_to_online_store(feature_view_name='docling_feature_view', df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abc1f56c-9894-4c56-a51f-805d39fc96ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling/pipeline/standard_pdf_pipeline.py:76: DeprecationWarning: Field `generate_table_images` is deprecated. To obtain table images, set `PdfPipelineOptions.generate_page_images = True` before conversion and then use the `TableItem.get_image` function.\n",
      "  or self.pipeline_options.generate_table_images\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling_core/types/doc/document.py:3272: DeprecationWarning: deprecated\n",
      "  if not d.validate_tree(d.body) or not d.validate_tree(d.furniture):\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling/pipeline/standard_pdf_pipeline.py:268: DeprecationWarning: Field `generate_table_images` is deprecated. To obtain table images, set `PdfPipelineOptions.generate_page_images = True` before conversion and then use the `TableItem.get_image` function.\n",
      "  or self.pipeline_options.generate_table_images\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (928 > 512). Running this sequence through the model will result in indexing errors\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling_core/transforms/chunker/hybrid_chunker.py:176: UserWarning: Headers and captions for this chunk are longer than the total amount of size for the chunk, chunk will be ignored: doc_chunk.text='PubTabNet, Tags = 3. PubTabNet, Bbox = 3. PubTabNet, Size = 509k. PubTabNet, Format = PNG. FinTabNet, Tags = 3. FinTabNet, Bbox = 3. FinTabNet, Size = 112k. FinTabNet, Format = PDF. TableBank, Tags = 3. TableBank, Bbox = 7. TableBank, Size = 145k. TableBank, Format = JPEG. Combined-Tabnet(*), Tags = 3. Combined-Tabnet(*), Bbox = 3. Combined-Tabnet(*), Size = 400k. Combined-Tabnet(*), Format = PNG. Combined(**), Tags = 3. Combined(**), Bbox = 3. Combined(**), Size = 500k. Combined(**), Format = PNG. SynthTabNet, Tags = 3. SynthTabNet, Bbox = 3. SynthTabNet, Size = 600k. SynthTabNet, Format = PNG'\n",
      "  warnings.warn(\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling/pipeline/standard_pdf_pipeline.py:76: DeprecationWarning: Field `generate_table_images` is deprecated. To obtain table images, set `PdfPipelineOptions.generate_page_images = True` before conversion and then use the `TableItem.get_image` function.\n",
      "  or self.pipeline_options.generate_table_images\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling_core/types/doc/document.py:3272: DeprecationWarning: deprecated\n",
      "  if not d.validate_tree(d.body) or not d.validate_tree(d.furniture):\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling_core/transforms/chunker/hybrid_chunker.py:176: UserWarning: Headers and captions for this chunk are longer than the total amount of size for the chunk, chunk will be ignored: doc_chunk.text='6, #.dec-layers = 6. 6, Language.Language = OTSL HTML. 6, TEDs.simple = 0.965 0.969. 6, TEDs.complex = 0.934 0.927. 6, TEDs.all = 0.955 0.955. 6, mAP.(0.75) = 0.88 0.857. 6, Inference.time (secs) = 2.73 5.39. 4, #.dec-layers = 4. 4, Language.Language = OTSL HTML. 4, TEDs.simple = 0.938 0.952. 4, TEDs.complex = 0.904. 4, TEDs.all = 0.927. 4, mAP.(0.75) = 0.853. 4, Inference.time (secs) = 1.97. 2, #.dec-layers = . 2, Language.Language = OTSL. 2, TEDs.simple = 0.923. 2, TEDs.complex = 0.909. 2, TEDs.all = 0.938. 2, mAP.(0.75) = 0.843. 2, Inference.time (secs) = 3.77. , #.dec-layers = 4. , Language.Language = HTML. , TEDs.simple = 0.945. , TEDs.complex = 0.897 0.901. , TEDs.all = 0.915 0.931. , mAP.(0.75) = 0.859 0.834. , Inference.time (secs) = 1.91 3.81. 4, #.dec-layers = 2. 4, Language.Language = OTSL HTML. 4, TEDs.simple = 0.952 0.944. 4, TEDs.complex = 0.92 0.903. 4, TEDs.all = 0.942 0.931. 4, mAP.(0.75) = 0.857 0.824. 4, Inference.time (secs) = 1.22 2'\n",
      "  warnings.warn(\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling/pipeline/standard_pdf_pipeline.py:76: DeprecationWarning: Field `generate_table_images` is deprecated. To obtain table images, set `PdfPipelineOptions.generate_page_images = True` before conversion and then use the `TableItem.get_image` function.\n",
      "  or self.pipeline_options.generate_table_images\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling_core/types/doc/document.py:3272: DeprecationWarning: deprecated\n",
      "  if not d.validate_tree(d.body) or not d.validate_tree(d.furniture):\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling_core/transforms/chunker/hybrid_chunker.py:176: UserWarning: Headers and captions for this chunk are longer than the total amount of size for the chunk, chunk will be ignored: doc_chunk.text='6, #.dec-layers = 6. 6, Language.Language = OTSL HTML. 6, TEDs.simple = 0.965 0.969. 6, TEDs.complex = 0.934 0.927. 6, TEDs.all = 0.955 0.955. 6, mAP.(0.75) = 0.88 0.857. 6, Inference.time (secs) = 2.73 5.39. 4, #.dec-layers = 4. 4, Language.Language = OTSL HTML. 4, TEDs.simple = 0.938 0.952. 4, TEDs.complex = 0.904. 4, TEDs.all = 0.927. 4, mAP.(0.75) = 0.853. 4, Inference.time (secs) = 1.97. 2, #.dec-layers = . 2, Language.Language = OTSL. 2, TEDs.simple = 0.923 0.945. 2, TEDs.complex = 0.909 0.897. 2, TEDs.all = 0.938. 2, mAP.(0.75) = 0.843. 2, Inference.time (secs) = 3.77. , #.dec-layers = 4. , Language.Language = HTML. , TEDs.simple = . , TEDs.complex = 0.901. , TEDs.all = 0.915 0.931. , mAP.(0.75) = 0.859 0.834. , Inference.time (secs) = 1.91 3.81. 4, #.dec-layers = 2. 4, Language.Language = OTSL HTML. 4, TEDs.simple = 0.952 0.944. 4, TEDs.complex = 0.92 0.903. 4, TEDs.all = 0.942 0.931. 4, mAP.(0.75) = 0.857 0.824. 4, Inference.time (secs) = 1.22 2'\n",
      "  warnings.warn(\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling_core/transforms/chunker/hybrid_chunker.py:176: UserWarning: Headers and captions for this chunk are longer than the total amount of size for the chunk, chunk will be ignored: doc_chunk.text='PubTabNet, Language.Language = OTSL. PubTabNet, TEDs.simple = 0.965. PubTabNet, TEDs.complex = 0.934. PubTabNet, TEDs.all = 0.955. PubTabNet, mAP(0.75).mAP(0.75) = 0.88. PubTabNet, Inference time (secs).Inference time (secs) = 2.73. PubTabNet, Language.Language = HTML. PubTabNet, TEDs.simple = 0.969. PubTabNet, TEDs.complex = 0.927. PubTabNet, TEDs.all = 0.955. PubTabNet, mAP(0.75).mAP(0.75) = 0.857. PubTabNet, Inference time (secs).Inference time (secs) = 5.39. FinTabNet, Language.Language = OTSL. FinTabNet, TEDs.simple = 0.955. FinTabNet, TEDs.complex = 0.961. FinTabNet, TEDs.all = 0.959. FinTabNet, mAP(0.75).mAP(0.75) = 0.862. FinTabNet, Inference time (secs).Inference time (secs) = 1.85. FinTabNet, Language.Language = HTML. FinTabNet, TEDs.simple = 0.917. FinTabNet, TEDs.complex = 0.922. FinTabNet, TEDs.all = 0.92. FinTabNet, mAP(0.75).mAP(0.75) = 0.722. FinTabNet, Inference time (secs).Inference time (secs) = 3.26. PubTables-1M, Language.Language = OTSL. PubTables-1M, TEDs.simple = 0.987. PubTables-1M, TEDs.complex = 0.964. PubTables-1M, TEDs.all = 0.977. PubTables-1M, mAP(0.75).mAP(0.75) = 0.896. PubTables-1M, Inference time (secs).Inference time (secs) = 1.79. PubTables-1M, Language.Language = HTML. PubTables-1M, TEDs.simple = 0.983. PubTables-1M, TEDs.complex = 0.944. PubTables-1M, TEDs.all = 0.966. PubTables-1M, mAP(0.75).mAP(0.75) = 0.889. PubTables-1M, Inference time (secs).Inference time (secs) = 3.26'\n",
      "  warnings.warn(\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling/pipeline/standard_pdf_pipeline.py:76: DeprecationWarning: Field `generate_table_images` is deprecated. To obtain table images, set `PdfPipelineOptions.generate_page_images = True` before conversion and then use the `TableItem.get_image` function.\n",
      "  or self.pipeline_options.generate_table_images\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling_core/types/doc/document.py:3272: DeprecationWarning: deprecated\n",
      "  if not d.validate_tree(d.body) or not d.validate_tree(d.furniture):\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling/pipeline/standard_pdf_pipeline.py:76: DeprecationWarning: Field `generate_table_images` is deprecated. To obtain table images, set `PdfPipelineOptions.generate_page_images = True` before conversion and then use the `TableItem.get_image` function.\n",
      "  or self.pipeline_options.generate_table_images\n",
      "/Users/farceo/dev/feast/.venv/lib/python3.10/site-packages/docling_core/types/doc/document.py:3272: DeprecationWarning: deprecated\n",
      "  if not d.validate_tree(d.body) or not d.validate_tree(d.furniture):\n",
      "/Users/farceo/dev/feast/sdk/python/feast/feature_store.py:1575: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  ).applymap(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_to_online_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_view_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdocling_transform_docs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/feast/sdk/python/feast/feature_store.py:1646\u001b[0m, in \u001b[0;36mFeatureStore.write_to_online_store\u001b[0;34m(self, feature_view_name, df, inputs, allow_registry_cache)\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrite_to_online_store\u001b[39m(\n\u001b[1;32m   1630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1631\u001b[0m     feature_view_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1634\u001b[0m     allow_registry_cache: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1635\u001b[0m ):\n\u001b[1;32m   1636\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1637\u001b[0m \u001b[38;5;124;03m    Persists a dataframe to the online store.\u001b[39;00m\n\u001b[1;32m   1638\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1643\u001b[0m \u001b[38;5;124;03m        allow_registry_cache (optional): Whether to allow retrieving feature views from a cached registry.\u001b[39;00m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1646\u001b[0m     feature_view, df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_feature_view_and_df_for_online_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_view_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_view_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_registry_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_registry_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1652\u001b[0m     provider \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_provider()\n\u001b[1;32m   1653\u001b[0m     provider\u001b[38;5;241m.\u001b[39mingest_df(feature_view, df)\n",
      "File \u001b[0;32m~/dev/feast/sdk/python/feast/feature_store.py:1603\u001b[0m, in \u001b[0;36mFeatureStore._get_feature_view_and_df_for_online_write\u001b[0;34m(self, feature_view_name, df, inputs, allow_registry_cache)\u001b[0m\n\u001b[1;32m   1601\u001b[0m         transformed_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(transformed_data)\n\u001b[1;32m   1602\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1603\u001b[0m         transformed_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtransformed_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m            \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1610\u001b[0m     \u001b[38;5;66;03m# overwrite any transformed features and update the dictionary\u001b[39;00m\n\u001b[1;32m   1611\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m input_dict:\n",
      "File \u001b[0;32m~/dev/feast/.venv/lib/python3.10/site-packages/pandas/core/reshape/merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    171\u001b[0m         left_df,\n\u001b[1;32m    172\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    183\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/feast/.venv/lib/python3.10/site-packages/pandas/core/reshape/merge.py:886\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[0;32m--> 886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[1;32m    889\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    890\u001b[0m )\n\u001b[1;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n",
      "File \u001b[0;32m~/dev/feast/.venv/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1151\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     join_index, right_indexer, left_indexer \u001b[38;5;241m=\u001b[39m _left_join_on_index(\n\u001b[1;32m   1148\u001b[0m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1151\u001b[0m     (left_indexer, right_indexer) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index:\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/dev/feast/.venv/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1125\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_indexers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# make mypy happy\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masof\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_join_indexers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhow\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/feast/.venv/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1719\u001b[0m, in \u001b[0;36mget_join_indexers\u001b[0;34m(left_keys, right_keys, sort, how)\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(left_keys) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m   1715\u001b[0m     right_keys\n\u001b[1;32m   1716\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft_keys and right_keys must be the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;66;03m# fast-path for empty left/right\u001b[39;00m\n\u001b[0;32m-> 1719\u001b[0m left_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mleft_keys\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m   1720\u001b[0m right_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(right_keys[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "store.write_to_online_store(feature_view_name='docling_transform_docs', df=mdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14453d0d-c6c4-46e2-9fde-ada4000947fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = store._provider._online_store._conn\n",
    "document_table = store._provider._online_store._conn.execute(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table' and name like '%docling%';\"\n",
    ").fetchall()[0][0]\n",
    "written_data = pd.read_sql_query(f\"select * from {document_table}\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93693782-7489-4373-81b0-226f47874473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_key</th>\n",
       "      <th>feature_name</th>\n",
       "      <th>value</th>\n",
       "      <th>vector_value</th>\n",
       "      <th>event_ts</th>\n",
       "      <th>created_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...</td>\n",
       "      <td>file_name</td>\n",
       "      <td>b'\\x12\\x10right_to_left_03'</td>\n",
       "      <td>right_to_left_03</td>\n",
       "      <td>2025-03-26 22:50:32</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...</td>\n",
       "      <td>raw_chunk_markdown</td>\n",
       "      <td>b'\\x12;2-5 -\\xd8\\xa7\\xd8\\xb3\\xd8\\xaa\\xd8\\xa7\\x...</td>\n",
       "      <td>2-5 -استاندارد ک الا\\nنام استاندارد</td>\n",
       "      <td>2025-03-26 22:50:32</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...</td>\n",
       "      <td>vector</td>\n",
       "      <td>b'\\x82\\x01\\x83\\x0c\\n\\x80\\x0c\\x96d\\xd2\\xbc\\x03h...</td>\n",
       "      <td>b'\\x96d\\xd2\\xbc\\x03h\\xae=\\x16(E=\\x8bX\\'\\xbd\\x1...</td>\n",
       "      <td>2025-03-26 22:50:32</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...</td>\n",
       "      <td>file_name</td>\n",
       "      <td>b'\\x12\\x10right_to_left_03'</td>\n",
       "      <td>right_to_left_03</td>\n",
       "      <td>2025-03-26 22:50:32</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...</td>\n",
       "      <td>raw_chunk_markdown</td>\n",
       "      <td>b'\\x12\\x94\\x012-5 -\\xd8\\xa7\\xd8\\xb3\\xd8\\xaa\\xd...</td>\n",
       "      <td>2-5 -استاندارد ک الا\\nشمشه  و  شمشال  توليد  ش...</td>\n",
       "      <td>2025-03-26 22:50:32</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...</td>\n",
       "      <td>raw_chunk_markdown</td>\n",
       "      <td>b'\\x12\\x8e\\x01TableFormer predicted structure\\...</td>\n",
       "      <td>TableFormer predicted structure\\n= . Ki-67 pro...</td>\n",
       "      <td>2025-03-26 22:50:32</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...</td>\n",
       "      <td>vector</td>\n",
       "      <td>b'\\x82\\x01\\x83\\x0c\\n\\x80\\x0c\\xd9\\x1as\\xbd$\\x01...</td>\n",
       "      <td>b'\\xd9\\x1as\\xbd$\\x01\\xa6\\xbc\\xe7\\x04Y\\xbd\\xd3\\...</td>\n",
       "      <td>2025-03-26 22:50:32</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...</td>\n",
       "      <td>file_name</td>\n",
       "      <td>b'\\x12\\x0c2203.01017v2'</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>2025-03-26 22:50:32</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...</td>\n",
       "      <td>raw_chunk_markdown</td>\n",
       "      <td>b'\\x12\\x8a\\x01TableFormer predicted structure\\...</td>\n",
       "      <td>TableFormer predicted structure\\nFigure 16: Ex...</td>\n",
       "      <td>2025-03-26 22:50:32</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...</td>\n",
       "      <td>vector</td>\n",
       "      <td>b'\\x82\\x01\\x83\\x0c\\n\\x80\\x0c`\\xc6[\\xbd}\\xf4\\t\\...</td>\n",
       "      <td>b'`\\xc6[\\xbd}\\xf4\\t\\xbd\\xa9\\xf2&gt;&lt;\\xe5\\xbb9=m\\x...</td>\n",
       "      <td>2025-03-26 22:50:32</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1056 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             entity_key        feature_name  \\\n",
       "0     b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...           file_name   \n",
       "1     b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...  raw_chunk_markdown   \n",
       "2     b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...              vector   \n",
       "3     b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...           file_name   \n",
       "4     b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...  raw_chunk_markdown   \n",
       "...                                                 ...                 ...   \n",
       "1051  b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...  raw_chunk_markdown   \n",
       "1052  b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...              vector   \n",
       "1053  b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...           file_name   \n",
       "1054  b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...  raw_chunk_markdown   \n",
       "1055  b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x08\\x00\\x00...              vector   \n",
       "\n",
       "                                                  value  \\\n",
       "0                           b'\\x12\\x10right_to_left_03'   \n",
       "1     b'\\x12;2-5 -\\xd8\\xa7\\xd8\\xb3\\xd8\\xaa\\xd8\\xa7\\x...   \n",
       "2     b'\\x82\\x01\\x83\\x0c\\n\\x80\\x0c\\x96d\\xd2\\xbc\\x03h...   \n",
       "3                           b'\\x12\\x10right_to_left_03'   \n",
       "4     b'\\x12\\x94\\x012-5 -\\xd8\\xa7\\xd8\\xb3\\xd8\\xaa\\xd...   \n",
       "...                                                 ...   \n",
       "1051  b'\\x12\\x8e\\x01TableFormer predicted structure\\...   \n",
       "1052  b'\\x82\\x01\\x83\\x0c\\n\\x80\\x0c\\xd9\\x1as\\xbd$\\x01...   \n",
       "1053                            b'\\x12\\x0c2203.01017v2'   \n",
       "1054  b'\\x12\\x8a\\x01TableFormer predicted structure\\...   \n",
       "1055  b'\\x82\\x01\\x83\\x0c\\n\\x80\\x0c`\\xc6[\\xbd}\\xf4\\t\\...   \n",
       "\n",
       "                                           vector_value            event_ts  \\\n",
       "0                                      right_to_left_03 2025-03-26 22:50:32   \n",
       "1                   2-5 -استاندارد ک الا\\nنام استاندارد 2025-03-26 22:50:32   \n",
       "2     b'\\x96d\\xd2\\xbc\\x03h\\xae=\\x16(E=\\x8bX\\'\\xbd\\x1... 2025-03-26 22:50:32   \n",
       "3                                      right_to_left_03 2025-03-26 22:50:32   \n",
       "4     2-5 -استاندارد ک الا\\nشمشه  و  شمشال  توليد  ش... 2025-03-26 22:50:32   \n",
       "...                                                 ...                 ...   \n",
       "1051  TableFormer predicted structure\\n= . Ki-67 pro... 2025-03-26 22:50:32   \n",
       "1052  b'\\xd9\\x1as\\xbd$\\x01\\xa6\\xbc\\xe7\\x04Y\\xbd\\xd3\\... 2025-03-26 22:50:32   \n",
       "1053                                       2203.01017v2 2025-03-26 22:50:32   \n",
       "1054  TableFormer predicted structure\\nFigure 16: Ex... 2025-03-26 22:50:32   \n",
       "1055  b'`\\xc6[\\xbd}\\xf4\\t\\xbd\\xa9\\xf2><\\xe5\\xbb9=m\\x... 2025-03-26 22:50:32   \n",
       "\n",
       "     created_ts  \n",
       "0          None  \n",
       "1          None  \n",
       "2          None  \n",
       "3          None  \n",
       "4          None  \n",
       "...         ...  \n",
       "1051       None  \n",
       "1052       None  \n",
       "1053       None  \n",
       "1054       None  \n",
       "1055       None  \n",
       "\n",
       "[1056 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "written_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b836e5b1-1fe2-4e9d-8c9a-bdc91da8254e",
   "metadata": {},
   "source": [
    "### Step 5b: Inspect materialized features\n",
    "\n",
    "Note that now there are `online_store.db` and `registry.db`, which store the materialized features and schema information, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1307b1aa-fecf-4adf-aafc-f65d89ca735c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id_pk</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>created_ts</th>\n",
       "      <th>event_ts</th>\n",
       "      <th>file_name</th>\n",
       "      <th>raw_chunk_markdown</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0100000002000000080000006368756e6b5f6964020000...</td>\n",
       "      <td>002bce0097246931724ae35b1e1a0d13fbb2c1a97e6c04...</td>\n",
       "      <td>0</td>\n",
       "      <td>1740914705958118</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\n95% on complex tables.</td>\n",
       "      <td>0.051321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0100000002000000080000006368756e6b5f6964020000...</td>\n",
       "      <td>002bce0097246931724ae35b1e1a0d13fbb2c1a97e6c04...</td>\n",
       "      <td>0</td>\n",
       "      <td>1740914705958118</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\n95% on complex tables.</td>\n",
       "      <td>0.091583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0100000002000000080000006368756e6b5f6964020000...</td>\n",
       "      <td>002bce0097246931724ae35b1e1a0d13fbb2c1a97e6c04...</td>\n",
       "      <td>0</td>\n",
       "      <td>1740914705958118</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\n95% on complex tables.</td>\n",
       "      <td>-0.039993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0100000002000000080000006368756e6b5f6964020000...</td>\n",
       "      <td>002bce0097246931724ae35b1e1a0d13fbb2c1a97e6c04...</td>\n",
       "      <td>0</td>\n",
       "      <td>1740914705958118</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\n95% on complex tables.</td>\n",
       "      <td>0.028728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0100000002000000080000006368756e6b5f6964020000...</td>\n",
       "      <td>002bce0097246931724ae35b1e1a0d13fbb2c1a97e6c04...</td>\n",
       "      <td>0</td>\n",
       "      <td>1740914705958118</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>a. Picture of a table:\\n95% on complex tables.</td>\n",
       "      <td>-0.003588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         chunk_id_pk  \\\n",
       "0  0100000002000000080000006368756e6b5f6964020000...   \n",
       "1  0100000002000000080000006368756e6b5f6964020000...   \n",
       "2  0100000002000000080000006368756e6b5f6964020000...   \n",
       "3  0100000002000000080000006368756e6b5f6964020000...   \n",
       "4  0100000002000000080000006368756e6b5f6964020000...   \n",
       "\n",
       "                                            chunk_id  created_ts  \\\n",
       "0  002bce0097246931724ae35b1e1a0d13fbb2c1a97e6c04...           0   \n",
       "1  002bce0097246931724ae35b1e1a0d13fbb2c1a97e6c04...           0   \n",
       "2  002bce0097246931724ae35b1e1a0d13fbb2c1a97e6c04...           0   \n",
       "3  002bce0097246931724ae35b1e1a0d13fbb2c1a97e6c04...           0   \n",
       "4  002bce0097246931724ae35b1e1a0d13fbb2c1a97e6c04...           0   \n",
       "\n",
       "           event_ts     file_name  \\\n",
       "0  1740914705958118  2203.01017v2   \n",
       "1  1740914705958118  2203.01017v2   \n",
       "2  1740914705958118  2203.01017v2   \n",
       "3  1740914705958118  2203.01017v2   \n",
       "4  1740914705958118  2203.01017v2   \n",
       "\n",
       "                               raw_chunk_markdown    vector  \n",
       "0  a. Picture of a table:\\n95% on complex tables.  0.051321  \n",
       "1  a. Picture of a table:\\n95% on complex tables.  0.091583  \n",
       "2  a. Picture of a table:\\n95% on complex tables. -0.039993  \n",
       "3  a. Picture of a table:\\n95% on complex tables.  0.028728  \n",
       "4  a. Picture of a table:\\n95% on complex tables. -0.003588  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pymilvus_client = store._provider._online_store._connect(store.config)\n",
    "COLLECTION_NAME = pymilvus_client.list_collections()[0]\n",
    "\n",
    "milvus_query_result = pymilvus_client.query(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    filter=\"file_name == '2203.01017v2'\",\n",
    ")\n",
    "pd.DataFrame(milvus_query_result[0]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf3921-e775-46b7-9915-d18c6592586f",
   "metadata": {},
   "source": [
    "### Quick note on entity keys\n",
    "Note from the above command that the online store indexes by `entity_key`. \n",
    "\n",
    "[Entity keys](https://docs.feast.dev/getting-started/concepts/entity#entity-key) include a list of all entities needed (e.g. all relevant primary keys) to generate the feature vector. In this case, this is a serialized version of the `driver_id`. We use this later to fetch all features for a given driver at inference time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f6e4a-2d37-4428-8dba-81620a65c2ad",
   "metadata": {},
   "source": [
    "## Step 6: Embedding a query using PyTorch and Sentence Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b4e67d-6f94-4532-b107-abc4c0f002f1",
   "metadata": {},
   "source": [
    "During inference (e.g., during when a user submits a chat message) we need to embed the input text. This can be thought of as a feature transformation of the input data. In this example, we'll do this with a small Sentence Transformer from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c7040e5-e09b-4d64-bd29-3df5e2daa6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding_model = SentenceTransformer(EMBED_MODEL_ID)\n",
    "\n",
    "def embed_chunk(inputs):\n",
    "    output = {\n",
    "        \"query_embedding\": embedding_model.encode([\n",
    "            inputs[\"query_string\"]], normalize_embeddings=True,\n",
    "        ).tolist()[0]\n",
    "    }\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a69d55c-6f70-4f63-a167-0a38e840e3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.011573407799005508,\n",
       " 0.025136204436421394,\n",
       " -0.03670184686779976,\n",
       " 0.05932486802339554,\n",
       " -0.0071490369737148285,\n",
       " -0.04119417816400528,\n",
       " 0.07708743214607239,\n",
       " 0.037442512810230255,\n",
       " 0.012449025176465511,\n",
       " -0.006117636803537607]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_chunk({\"query_string\": \"test\"})['query_embedding'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67868cdf-04e9-4086-bed8-050e4902ed71",
   "metadata": {},
   "source": [
    "## Step 7: Fetching real-time vectors and data for online inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b9ae94-7daa-4d56-8bca-9339d09cd1ed",
   "metadata": {},
   "source": [
    "At inference time, we need to use vector similarity search through the document embeddings from the online feature store using `retrieve_online_documents_v2()` while passing the embedded query. These feature vectors can then be fed into the context of the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "583ffffc-d1c8-450c-8997-376bd3960f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahmed Nassar, Nikolaos Livathinos, Maksym Lysak, Peter Staar IBM Research\n",
      "{ ahn,nli,mly,taa @zurich.ibm.com }\n"
     ]
    }
   ],
   "source": [
    "sample_query = df['raw_chunk_markdown'].values[0] \n",
    "print(sample_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c76a526-35dc-4af5-bd46-d181e3a8c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note we can enhance this special case to embed within the feature server, optionally.\n",
    "query_embedding = embed_chunk({\"query_string\": sample_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3099708-409b-4d9e-b1d6-8ad86de6fde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector</th>\n",
       "      <th>file_name</th>\n",
       "      <th>raw_chunk_markdown</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.056879762560129166, 0.01667858101427555, -...</td>\n",
       "      <td>redp5110_sampled</td>\n",
       "      <td>1.2  Current state of IBM i security\\nthe empl...</td>\n",
       "      <td>246855c6650678a5b15f8e0cfa2d2670e249140ac2541e...</td>\n",
       "      <td>0.515772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.056879762560129166, 0.01667858101427555, -...</td>\n",
       "      <td>2203.01017v2</td>\n",
       "      <td>Ahmed Nassar, Nikolaos Livathinos, Maksym Lysa...</td>\n",
       "      <td>6385912fa27a8dd602cea2afaa3ecc9a27229ebd508661...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.056879762560129166, 0.01667858101427555, -...</td>\n",
       "      <td>redp5110_sampled</td>\n",
       "      <td>We build confident, satisfied clients\\nNo one ...</td>\n",
       "      <td>8e0a5ad8fd2216eff21b4ac27efb018586ceb9ed4e3a34...</td>\n",
       "      <td>0.510600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              vector         file_name  \\\n",
       "0  [-0.056879762560129166, 0.01667858101427555, -...  redp5110_sampled   \n",
       "1  [-0.056879762560129166, 0.01667858101427555, -...      2203.01017v2   \n",
       "2  [-0.056879762560129166, 0.01667858101427555, -...  redp5110_sampled   \n",
       "\n",
       "                                  raw_chunk_markdown  \\\n",
       "0  1.2  Current state of IBM i security\\nthe empl...   \n",
       "1  Ahmed Nassar, Nikolaos Livathinos, Maksym Lysa...   \n",
       "2  We build confident, satisfied clients\\nNo one ...   \n",
       "\n",
       "                                            chunk_id  distance  \n",
       "0  246855c6650678a5b15f8e0cfa2d2670e249140ac2541e...  0.515772  \n",
       "1  6385912fa27a8dd602cea2afaa3ecc9a27229ebd508661...  1.000000  \n",
       "2  8e0a5ad8fd2216eff21b4ac27efb018586ceb9ed4e3a34...  0.510600  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Retrieve top k documents\n",
    "context_data = store.retrieve_online_documents_v2(\n",
    "    features=[\n",
    "        \"docling_feature_view:vector\",\n",
    "        \"docling_feature_view:file_name\",\n",
    "        \"docling_feature_view:raw_chunk_markdown\",\n",
    "        \"docling_feature_view:chunk_id\",\n",
    "    ],\n",
    "    query=query_embedding['query_embedding'],\n",
    "    top_k=3,\n",
    "    distance_metric='COSINE',\n",
    ").to_df()\n",
    "\n",
    "display(context_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6aa7d24-4a80-48ea-9732-0818f333dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    " def format_documents(context_df):\n",
    "    output_context = \"\"\n",
    "    \n",
    "    # Remove duplicates based on 'chunk_id' (ensuring unique document chunks)\n",
    "    unique_documents = context_df.drop_duplicates(subset=[\"chunk_id\"])[\"raw_chunk_markdown\"]\n",
    "    \n",
    "    # Format each document\n",
    "    for i, document_text in enumerate(unique_documents):\n",
    "        output_context += f\"****START DOCUMENT {i}****\\n\"\n",
    "        output_context += f\"document = {{ {document_text.strip()} }}\\n\"\n",
    "        output_context += f\"****END DOCUMENT {i}****\\n\\n\"\n",
    "    \n",
    "    return output_context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5dd668d6-da81-48a2-a841-a9df1804bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_CONTEXT = format_documents(context_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3978561a-79a0-48bb-86ca-d81293a0e618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****START DOCUMENT 0****\n",
      "document = { 1.2  Current state of IBM i security\n",
      "the employees that they manage. }\n",
      "****END DOCUMENT 0****\n",
      "\n",
      "****START DOCUMENT 1****\n",
      "document = { Ahmed Nassar, Nikolaos Livathinos, Maksym Lysak, Peter Staar IBM Research\n",
      "{ ahn,nli,mly,taa @zurich.ibm.com } }\n",
      "****END DOCUMENT 1****\n",
      "\n",
      "****START DOCUMENT 2****\n",
      "document = { We build confident, satisfied clients\n",
      "No one else has the vast consulting experiences, skills sharing and renown service offerings to do what we can do for you.\n",
      "Because no one else is IBM. }\n",
      "****END DOCUMENT 2****\n"
     ]
    }
   ],
   "source": [
    "print(RAG_CONTEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09cad16f-4078-42de-80ee-2672dae5608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_PROMPT = f\"\"\"\n",
    "You are an assistant for answering questions about a series of documents. You will be provided documentation from different documents. Provide a conversational answer.\n",
    "If you don't know the answer, just say \"I do not know.\" Don't make up an answer.\n",
    "\n",
    "Here are document(s) you should use when answer the users question:\n",
    "{RAG_CONTEXT}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d4b1739-e686-4d77-9f25-1cdec66f3773",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Who are the authors of the paper?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7bb4a000-8ef3-4006-9c61-7d76fa865d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da814147-9c78-4906-a84a-78fc88c2fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": FULL_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68cbd8df-af73-4dbe-97a9-f3cd89f36f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The authors of the paper are Ahmed Nassar, Nikolaos Livathinos, Maksym Lysak, and Peter Staar from IBM Research.\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([c.message.content for c in response.choices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f01627-533b-49b0-9814-292360d064c6",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

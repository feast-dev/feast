{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2bd159-b8a0-4ce2-92e3-3111a847e136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating a new Feast repository in \u001b[1m\u001b[32m/Users/franciscojavierarceo/GitHub/feast/examples/data-quality-monitoring/dqm_repo\u001b[0m.\n",
      "\n",
      "/Users/franciscojavierarceo/GitHub/feast/examples/data-quality-monitoring/dqm_repo\n"
     ]
    }
   ],
   "source": [
    "!rm -rf dqm_repo\n",
    "!feast init dqm_repo\n",
    "%cd dqm_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ddad2d-0440-43f8-8cc1-bcc0a8736f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>conv_rate</th>\n",
       "      <th>acc_rate</th>\n",
       "      <th>avg_daily_trips</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-26 21:00:00+00:00</td>\n",
       "      <td>1005</td>\n",
       "      <td>0.675813</td>\n",
       "      <td>0.697865</td>\n",
       "      <td>463</td>\n",
       "      <td>2022-08-10 21:06:22.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-26 22:00:00+00:00</td>\n",
       "      <td>1005</td>\n",
       "      <td>0.707445</td>\n",
       "      <td>0.642702</td>\n",
       "      <td>927</td>\n",
       "      <td>2022-08-10 21:06:22.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-26 23:00:00+00:00</td>\n",
       "      <td>1005</td>\n",
       "      <td>0.237603</td>\n",
       "      <td>0.195165</td>\n",
       "      <td>366</td>\n",
       "      <td>2022-08-10 21:06:22.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-27 00:00:00+00:00</td>\n",
       "      <td>1005</td>\n",
       "      <td>0.111497</td>\n",
       "      <td>0.292317</td>\n",
       "      <td>410</td>\n",
       "      <td>2022-08-10 21:06:22.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-27 01:00:00+00:00</td>\n",
       "      <td>1005</td>\n",
       "      <td>0.965894</td>\n",
       "      <td>0.930423</td>\n",
       "      <td>816</td>\n",
       "      <td>2022-08-10 21:06:22.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>2022-08-10 19:00:00+00:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.229680</td>\n",
       "      <td>0.490494</td>\n",
       "      <td>993</td>\n",
       "      <td>2022-08-10 21:06:22.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>2022-08-10 20:00:00+00:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.025623</td>\n",
       "      <td>0.181108</td>\n",
       "      <td>430</td>\n",
       "      <td>2022-08-10 21:06:22.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>2021-04-12 07:00:00+00:00</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.201743</td>\n",
       "      <td>0.193218</td>\n",
       "      <td>517</td>\n",
       "      <td>2022-08-10 21:06:22.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>2022-08-03 09:00:00+00:00</td>\n",
       "      <td>1003</td>\n",
       "      <td>0.072511</td>\n",
       "      <td>0.965429</td>\n",
       "      <td>690</td>\n",
       "      <td>2022-08-10 21:06:22.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>2022-08-03 09:00:00+00:00</td>\n",
       "      <td>1003</td>\n",
       "      <td>0.072511</td>\n",
       "      <td>0.965429</td>\n",
       "      <td>690</td>\n",
       "      <td>2022-08-10 21:06:22.761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1807 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               event_timestamp  driver_id  conv_rate  acc_rate  \\\n",
       "0    2022-07-26 21:00:00+00:00       1005   0.675813  0.697865   \n",
       "1    2022-07-26 22:00:00+00:00       1005   0.707445  0.642702   \n",
       "2    2022-07-26 23:00:00+00:00       1005   0.237603  0.195165   \n",
       "3    2022-07-27 00:00:00+00:00       1005   0.111497  0.292317   \n",
       "4    2022-07-27 01:00:00+00:00       1005   0.965894  0.930423   \n",
       "...                        ...        ...        ...       ...   \n",
       "1802 2022-08-10 19:00:00+00:00       1001   0.229680  0.490494   \n",
       "1803 2022-08-10 20:00:00+00:00       1001   0.025623  0.181108   \n",
       "1804 2021-04-12 07:00:00+00:00       1001   0.201743  0.193218   \n",
       "1805 2022-08-03 09:00:00+00:00       1003   0.072511  0.965429   \n",
       "1806 2022-08-03 09:00:00+00:00       1003   0.072511  0.965429   \n",
       "\n",
       "      avg_daily_trips                 created  \n",
       "0                 463 2022-08-10 21:06:22.761  \n",
       "1                 927 2022-08-10 21:06:22.761  \n",
       "2                 366 2022-08-10 21:06:22.761  \n",
       "3                 410 2022-08-10 21:06:22.761  \n",
       "4                 816 2022-08-10 21:06:22.761  \n",
       "...               ...                     ...  \n",
       "1802              993 2022-08-10 21:06:22.761  \n",
       "1803              430 2022-08-10 21:06:22.761  \n",
       "1804              517 2022-08-10 21:06:22.761  \n",
       "1805              690 2022-08-10 21:06:22.761  \n",
       "1806              690 2022-08-10 21:06:22.761  \n",
       "\n",
       "[1807 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_parquet(\"data/driver_stats.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccec02a4-758a-41f4-9dd7-cf79e6be162a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created entity \u001b[1m\u001b[32mdriver\u001b[0m\n",
      "Created feature view \u001b[1m\u001b[32mdriver_hourly_stats\u001b[0m\n",
      "Created feature service \u001b[1m\u001b[32mdriver_activity\u001b[0m\n",
      "\n",
      "Created sqlite table \u001b[1m\u001b[32mdqm_repo_driver_hourly_stats\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!feast apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e31c15-396f-46df-9d53-57bcb305878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "from feast import FeatureStore\n",
    "from feast.infra.offline_stores.file_source import SavedDatasetFileStorage\n",
    "from feast.dqm.profilers.ge_profiler import ge_profiler\n",
    "from great_expectations.dataset import PandasDataset\n",
    "from great_expectations.core.expectation_suite import ExpectationSuite\n",
    "\n",
    "# The entity dataframe is the dataframe we want to enrich with feature values\n",
    "entity_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"driver_id\": [1001, 1002, 1003],\n",
    "        \"label_driver_reported_satisfaction\": [1, 5, 3], \n",
    "        \"event_timestamp\": [\n",
    "            datetime.now() - timedelta(minutes=11),\n",
    "            datetime.now() - timedelta(minutes=36),\n",
    "            datetime.now() - timedelta(minutes=73),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "store = FeatureStore(repo_path=\".\")\n",
    "\n",
    "training_data_job = store.get_historical_features(\n",
    "    entity_df=entity_df,\n",
    "    features=[\n",
    "        \"driver_hourly_stats:conv_rate\",\n",
    "        \"driver_hourly_stats:acc_rate\",\n",
    "        \"driver_hourly_stats:avg_daily_trips\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48117c04-5601-4807-8ebe-dbedddd8c68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_id</th>\n",
       "      <th>label_driver_reported_satisfaction</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>conv_rate</th>\n",
       "      <th>acc_rate</th>\n",
       "      <th>avg_daily_trips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-08-10 19:53:51.637185+00:00</td>\n",
       "      <td>0.754099</td>\n",
       "      <td>0.830307</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-08-10 20:30:51.637183+00:00</td>\n",
       "      <td>0.025148</td>\n",
       "      <td>0.506514</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-08-10 20:55:51.637174+00:00</td>\n",
       "      <td>0.025623</td>\n",
       "      <td>0.181108</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   driver_id  label_driver_reported_satisfaction  \\\n",
       "0       1003                                   3   \n",
       "1       1002                                   5   \n",
       "2       1001                                   1   \n",
       "\n",
       "                   event_timestamp  conv_rate  acc_rate  avg_daily_trips  \n",
       "0 2022-08-10 19:53:51.637185+00:00   0.754099  0.830307              823  \n",
       "1 2022-08-10 20:30:51.637183+00:00   0.025148  0.506514              164  \n",
       "2 2022-08-10 20:55:51.637174+00:00   0.025623  0.181108              430  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_job.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f5345c5-5410-4ae3-8fc6-46440bb8a61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franciscojavierarceo/GitHub/feast/sdk/python/feast/feature_store.py:1127: RuntimeWarning: Saving dataset is an experimental feature. This API is unstable and it could and most probably will be changed in the future. We do not guarantee that future changes will maintain backward compatibility.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<SavedDataset(name = reference_dataset, features = ['driver_hourly_stats:conv_rate', 'driver_hourly_stats:acc_rate', 'driver_hourly_stats:avg_daily_trips'], join_keys = ['driver_id', 'label_driver_reported_satisfaction'], storage = <feast.infra.offline_stores.file_source.SavedDatasetFileStorage object at 0x13f124bb0>, full_feature_names = False, tags = {}, feature_service_name = None, _retrieval_job = <feast.infra.offline_stores.file.FileRetrievalJob object at 0x13f1248e0>, min_event_timestamp = 2022-08-10 19:53:51.637185+00:00, max_event_timestamp = 2022-08-10 20:55:51.637174+00:00, created_timestamp = 2022-08-11 03:06:51.854923, last_updated_timestamp = 2022-08-11 03:06:51.854923)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_dataset = store.create_saved_dataset(\n",
    "    from_=training_data_job,\n",
    "    name=\"reference_dataset\",\n",
    "    storage=SavedDatasetFileStorage(path='data/driver_stats.parquet')\n",
    ")\n",
    "\n",
    "reference_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "903f06a2-0c60-4d18-b759-68d1e02ab8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franciscojavierarceo/GitHub/feast/sdk/python/feast/feature_store.py:1180: RuntimeWarning: Retrieving datasets is an experimental feature. This API is unstable and it could and most probably will be changed in the future. We do not guarantee that future changes will maintain backward compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@ge_profiler\n",
    "def user_features_profiler(dataset: PandasDataset) -> ExpectationSuite:\n",
    "    print(dataset.columns)\n",
    "    dataset.expect_column_to_exist(\"driver_id\")\n",
    "    dataset.expect_column_values_to_be_between(\"driver_hourly_stats__avg_daily_trips\", 0, 1000)\n",
    "    dataset.expect_column_values_to_be_between(\"driver_hourly_stats__conv_rate\", 0, 1)\n",
    "    dataset.expect_column_values_to_be_between(\"driver_hourly_stats__acc_rate\", 0, 1)\n",
    "    return dataset.get_expectation_suite()\n",
    "\n",
    "ds = store.get_saved_dataset('reference_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ac4c831-34e1-4426-bbf0-d82fdc6d5276",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['created'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m validation_reference \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mas_reference(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_features_profiler\u001b[39m\u001b[38;5;124m'\u001b[39m, profiler\u001b[38;5;241m=\u001b[39muser_features_profiler)\n\u001b[0;32m----> 2\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_data_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_reference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_reference\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GitHub/feast/sdk/python/feast/infra/offline_stores/offline_store.py:82\u001b[0m, in \u001b[0;36mRetrievalJob.to_df\u001b[0;34m(self, validation_reference)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_df\u001b[39m(\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m, validation_reference: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidationReference\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     76\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    Return dataset as Pandas DataFrame synchronously including on demand transforms\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m        validation_reference: If provided resulting dataset will be validated against this reference profile.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m     features_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_df_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_demand_feature_views:\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;66;03m# TODO(adchia): Fix requirement to specify dependent feature views in feature_refs\u001b[39;00m\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m odfv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_demand_feature_views:\n",
      "File \u001b[0;32m~/GitHub/feast/sdk/python/feast/usage.py:287\u001b[0m, in \u001b[0;36mlog_exceptions_and_usage.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mtraceback \u001b[38;5;241m=\u001b[39m _trace_to_log(traceback)\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m traceback:\n\u001b[0;32m--> 287\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/GitHub/feast/sdk/python/feast/usage.py:276\u001b[0m, in \u001b[0;36mlog_exceptions_and_usage.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m ctx\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mupdate(attrs)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mexception:\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;66;03m# exception was already recorded\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/feast/sdk/python/feast/infra/offline_stores/file.py:78\u001b[0m, in \u001b[0;36mFileRetrievalJob._to_df_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;129m@log_exceptions_and_usage\u001b[39m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_df_internal\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# Only execute the evaluation function to build the final historical retrieval dataframe at the last moment.\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m     79\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/GitHub/feast/sdk/python/feast/infra/offline_stores/file.py:226\u001b[0m, in \u001b[0;36mFileOfflineStore.get_historical_features.<locals>.evaluate_historical_retrieval\u001b[0;34m()\u001b[0m\n\u001b[1;32m    222\u001b[0m all_join_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(all_join_keys \u001b[38;5;241m+\u001b[39m join_keys))\n\u001b[1;32m    224\u001b[0m df_to_join \u001b[38;5;241m=\u001b[39m _read_datasource(feature_view\u001b[38;5;241m.\u001b[39mbatch_source)\n\u001b[0;32m--> 226\u001b[0m df_to_join, timestamp_field \u001b[38;5;241m=\u001b[39m \u001b[43m_field_mapping\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_to_join\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_view\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_entity_key_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentity_df_event_timestamp_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_feature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m df_to_join \u001b[38;5;241m=\u001b[39m _merge(entity_df_with_features, df_to_join, join_keys)\n\u001b[1;32m    238\u001b[0m df_to_join \u001b[38;5;241m=\u001b[39m _normalize_timestamp(\n\u001b[1;32m    239\u001b[0m     df_to_join, timestamp_field, created_timestamp_column\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m~/GitHub/feast/sdk/python/feast/infra/offline_stores/file.py:539\u001b[0m, in \u001b[0;36m_field_mapping\u001b[0;34m(df_to_join, feature_view, features, right_entity_key_columns, entity_df_event_timestamp_col, timestamp_field, full_feature_names)\u001b[0m\n\u001b[1;32m    536\u001b[0m df_to_join \u001b[38;5;241m=\u001b[39m _run_dask_field_mapping(df_to_join, columns_map)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m# Select only the columns we need to join from the feature dataframe\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m df_to_join \u001b[38;5;241m=\u001b[39m \u001b[43mdf_to_join\u001b[49m\u001b[43m[\u001b[49m\u001b[43mright_entity_key_columns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    540\u001b[0m df_to_join \u001b[38;5;241m=\u001b[39m df_to_join\u001b[38;5;241m.\u001b[39mpersist()\n\u001b[1;32m    542\u001b[0m \u001b[38;5;66;03m# Make sure to not have duplicated columns\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/feast/venv/lib/python3.8/site-packages/dask/dataframe/core.py:4215\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4209\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc[key]\n\u001b[1;32m   4211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   4212\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m is_dask_collection(key) \u001b[38;5;129;01mand\u001b[39;00m (is_series_like(key) \u001b[38;5;129;01mor\u001b[39;00m is_index_like(key))\n\u001b[1;32m   4213\u001b[0m ):\n\u001b[1;32m   4214\u001b[0m     \u001b[38;5;66;03m# error is raised from pandas\u001b[39;00m\n\u001b[0;32m-> 4215\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_extract_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   4217\u001b[0m     dsk \u001b[38;5;241m=\u001b[39m partitionwise_graph(operator\u001b[38;5;241m.\u001b[39mgetitem, name, \u001b[38;5;28mself\u001b[39m, key)\n\u001b[1;32m   4218\u001b[0m     graph \u001b[38;5;241m=\u001b[39m HighLevelGraph\u001b[38;5;241m.\u001b[39mfrom_collections(name, dsk, dependencies\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m])\n",
      "File \u001b[0;32m~/GitHub/feast/venv/lib/python3.8/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/GitHub/feast/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/feast/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5842\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5845\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['created'] not in index\""
     ]
    }
   ],
   "source": [
    "validation_reference = ds.as_reference(name='user_features_profiler', profiler=user_features_profiler)\n",
    "_ = training_data_job.to_df(validation_reference=validation_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6726b-7c4a-4efe-8bf5-00e633a6fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_job.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf4fafb-8fb2-4f98-9bdd-3623eea92c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
